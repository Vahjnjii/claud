{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13185395,"sourceType":"datasetVersion","datasetId":8355649},{"sourceId":13203033,"sourceType":"datasetVersion","datasetId":8367542}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Part 1: Environment Setup and Package Installation**","metadata":{"_uuid":"8e38e58b-a397-4713-a24b-0569c45dcd6d","_cell_guid":"126cb8c3-9f67-4c7a-8917-5150414c0cd3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import time\nimport threading\nimport os\nimport sys\n\n# Notebook Auto-Termination Timer\nTERMINATION_TIME = 12 * 3600 + 5 * 60  # 12 hours 5 minutes in seconds\n\nprint(\"=\" * 60)\nprint(\"‚è±Ô∏è  NOTEBOOK AUTO-TERMINATION ENABLED\")\nprint(\"=\" * 60)\nprint(f\"‚è∞ This notebook will automatically terminate in 12 hours 5 minutes\")\nprint(f\"üïê Start time: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\nprint(\"=\" * 60)\n\ndef terminate_notebook():\n    \"\"\"Terminate the notebook after the specified time\"\"\"\n    time.sleep(TERMINATION_TIME)\n    print(\"\\n\" + \"=\" * 60)\n    print(\"‚è∞ TIME LIMIT REACHED - TERMINATING NOTEBOOK\")\n    print(\"=\" * 60)\n    os._exit(0)\n\n# Start termination timer in background thread\ntermination_thread = threading.Thread(target=terminate_notebook, daemon=True)\ntermination_thread.start()\n\nprint(\"‚úÖ Termination timer started successfully\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Environment Setup and Package Installation\nimport os\nimport sys\nfrom datetime import datetime\n\n# Fix environment variables first\nos.environ['XDG_RUNTIME_DIR'] = '/tmp/runtime-root'\nos.environ['PULSE_RUNTIME_PATH'] = '/tmp/pulse'\nos.environ['DISPLAY'] = ':99'\nos.environ['MPLBACKEND'] = 'Agg'\n\n# Create necessary directories\ntry:\n    os.makedirs('/tmp/runtime-root', exist_ok=True)\n    os.makedirs('/tmp/pulse', exist_ok=True)\nexcept:\n    pass\n\n# Install packages\nprint(\"Installing dependencies...\")\nimport subprocess\n\ndef install_if_missing(package_name, import_name=None):\n    if import_name is None:\n        import_name = package_name\n    try:\n        __import__(import_name)\n        print(f\"{package_name} already available\")\n    except ImportError:\n        print(f\"Installing {package_name}...\")\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name, \"-q\"])\n\ninstall_if_missing(\"moviepy\")\ninstall_if_missing(\"gradio\")\ninstall_if_missing(\"openai-whisper\", \"whisper\")\ninstall_if_missing(\"google-genai\", \"google.genai\")\n# Install kaggle package (without import check to avoid auto-authentication)\nprint(\"Installing kaggle package...\")\nsubprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"kaggle\", \"-q\"])\nprint(\"kaggle package installed\")\n\nprint(\"Setup complete!\")\n\n# Install system packages\nprint(\"Installing system packages...\")\ntry:\n    os.system(\"apt update -qq && apt install -y ffmpeg imagemagick libmagick++-dev -qq\")\nexcept Exception as e:\n    print(f\"System package installation warning: {e}\")\n\n# Fix ImageMagick policy\nprint(\"Configuring ImageMagick...\")\ntry:\n    policy_xml = '''<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE policymap [\n<!ELEMENT policymap (policy)*>\n<!ELEMENT policy (#PCDATA)>\n<!ATTLIST policy domain (delegate|coder|filter|path|resource) #IMPLIED>\n<!ATTLIST policy name CDATA #IMPLIED>\n<!ATTLIST policy pattern CDATA #IMPLIED>\n<!ATTLIST policy rights CDATA #IMPLIED>\n<!ATTLIST policy stealth (True|False) \"False\">\n<!ATTLIST policy value CDATA #IMPLIED>\n]>\n<policymap>\n  <policy domain=\"resource\" name=\"memory\" value=\"256MiB\"/>\n  <policy domain=\"resource\" name=\"map\" value=\"512MiB\"/>\n  <policy domain=\"resource\" name=\"width\" value=\"32KP\"/>\n  <policy domain=\"resource\" name=\"height\" value=\"32KP\"/>\n  <policy domain=\"resource\" name=\"area\" value=\"1GP\"/>\n  <policy domain=\"resource\" name=\"disk\" value=\"4GiB\"/>\n  <policy domain=\"coder\" rights=\"read|write\" pattern=\"PDF\" />\n  <policy domain=\"coder\" rights=\"read|write\" pattern=\"LABEL\" />\n  <policy domain=\"coder\" rights=\"read|write\" pattern=\"*\" />\n  <policy domain=\"path\" rights=\"read|write\" pattern=\"@*\" />\n</policymap>'''\n    \n    policy_paths = [\n        '/etc/ImageMagick-6/policy.xml',\n        '/etc/ImageMagick/policy.xml',\n        '/usr/local/etc/ImageMagick-6/policy.xml'\n    ]\n    \n    for policy_path in policy_paths:\n        try:\n            if os.path.exists(os.path.dirname(policy_path)):\n                with open(policy_path, 'w') as f:\n                    f.write(policy_xml)\n                print(f\"Updated policy at {policy_path}\")\n                break\n        except:\n            continue\nexcept Exception as e:\n    print(f\"ImageMagick policy update warning: {e}\")\n\n# Import necessary libraries\nimport random\nimport json\nimport shutil\nimport wave\nimport base64\nimport numpy as np\nimport urllib.request\nfrom functools import lru_cache\n\nfrom moviepy.editor import (VideoFileClip, AudioFileClip, TextClip, \n                            concatenate_videoclips, CompositeVideoClip, \n                            CompositeAudioClip, ImageClip, concatenate_audioclips)\nimport gradio as gr\nfrom PIL import Image, ImageDraw, ImageFilter, ImageFont\nfrom google import genai\nfrom google.genai import types\n\n# ADD THIS LINE - Import whisper after installation\nimport whisper\nprint(\"Whisper loaded successfully!\")","metadata":{"_uuid":"c43f8d4a-1387-40c8-97fc-4aeee4924cb8","_cell_guid":"1b1afa95-054a-4432-9de6-ba3d9d1443ca","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Part 2: Configuration and Global Variables**","metadata":{"_uuid":"e76afbdd-50e5-4e69-ba60-775fc78f7df7","_cell_guid":"250df066-ce4e-431b-917e-60c70c6f2d7e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Configuration and Global Variables\n# Define paths and global variables\ngeneration_cancelled = False\ncurrent_video_clip = None\nSTATUS_FILE = '/kaggle/working/generation_status.json'\nHISTORY_FILE = '/kaggle/working/video_history.json'\nOUTPUT_PATH = '/kaggle/working/exports'\nAPI_KEY_FILE = '/kaggle/working/api_key.txt'\nSTATE_FILE = '/kaggle/working/ui_state.json'\nBATCH_STATUS_FILE = '/kaggle/working/batch_status.json'\n\n# Create output directory\nos.makedirs(OUTPUT_PATH, exist_ok=True)\n\n# Available voices for TTS\nAVAILABLE_VOICES = {\n    \"Puck\": {\"name\": \"Puck\", \"description\": \"Young adult female (US)\"},\n    \"Charon\": {\"name\": \"Charon\", \"description\": \"Young adult male (US)\"},\n    \"Kore\": {\"name\": \"Kore\", \"description\": \"Young adult female (US)\"},\n    \"Fenrir\": {\"name\": \"Fenrir\", \"description\": \"Young adult male (US)\"},\n    \"Aoede\": {\"name\": \"Aoede\", \"description\": \"Young adult female (US)\"}\n}\n\n# Aspect ratio configurations\nASPECT_RATIOS = {\n    \"9:16 (Vertical)\": {\"ratio\": (9, 16), \"name\": \"9:16\"},\n    \"4:5 (Portrait)\": {\"ratio\": (4, 5), \"name\": \"4:5\"}, # üéØ NEWLY ADDED\n    \"16:9 (Horizontal)\": {\"ratio\": (16, 9), \"name\": \"16:9\"},\n    \"1:1 (Square)\": {\"ratio\": (1, 1), \"name\": \"1:1\"}\n}","metadata":{"_uuid":"8f68e161-8b6a-4d70-96e8-8bcbf2f99562","_cell_guid":"0e81a816-34ef-4397-90af-ec08628530eb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **PART 3 Expect ratio function**","metadata":{"_uuid":"d33766d7-1bb0-4c9b-8baf-d8b41eb9865f","_cell_guid":"5e8c435d-6ba0-47de-a6e9-452293949e7c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# ============================================================================\n# SECTION 1: Aspect Ratio Functions (COMPLETE REPLACEMENT)\n# ============================================================================\n# Replace the ENTIRE \"Aspect Ratio Functions\" cell with this:\n\n# Aspect Ratio Functions\ndef calculate_target_dimensions(aspect_ratio, quality):\n    \"\"\"Calculate target dimensions based on aspect ratio and quality\"\"\"\n    ratio_w, ratio_h = ASPECT_RATIOS[aspect_ratio][\"ratio\"]\n\n    if quality == \"High\":\n        if ratio_w == 9 and ratio_h == 16:  # Vertical\n            return 1080, 1920\n        elif ratio_w == 4 and ratio_h == 5: # Portrait 4:5\n            return 1080, 1350\n        elif ratio_w == 16 and ratio_h == 9:  # Horizontal\n            return 1920, 1080\n        else:  # Square\n            return 1080, 1080\n    elif quality == \"Standard\":\n        if ratio_w == 9 and ratio_h == 16:\n            return 720, 1280\n        elif ratio_w == 4 and ratio_h == 5: # Portrait 4:5\n            return 720, 900\n        elif ratio_w == 16 and ratio_h == 9:\n            return 1280, 720\n        else:\n            return 720, 720\n    else:  # Preview\n        if ratio_w == 9 and ratio_h == 16:\n            return 480, 854\n        elif ratio_w == 4 and ratio_h == 5: # Portrait 4:5\n            return 480, 600\n        elif ratio_w == 16 and ratio_h == 9:\n            return 854, 480\n        else:\n            return 480, 480\n\n\ndef adapt_vertical_to_format(clip, target_width, target_height, aspect_ratio):\n    \"\"\"\n    Adapt all clips to the target format, ensuring quality and correct aspect ratio.\n    For 9:16: Upscale and crop to fit the 1080x1920 frame without distortion.\n    For 16:9, 4:5, and 1:1: Add a panning animation.\n    \"\"\"\n    try:\n        ratio_name = ASPECT_RATIOS[aspect_ratio][\"name\"]\n\n        # Process 9:16 clips to guarantee resolution and aspect ratio.\n        if ratio_name == \"9:16\":\n            if clip.size == (target_width, target_height):\n                return clip\n\n            print(f\"  ‚öôÔ∏è Processing 9:16 clip: Resizing from {clip.size} to fit ({target_width}, {target_height}) without distortion.\")\n            scaled_clip = clip.resize(height=target_height)\n            cropped_clip = scaled_clip.crop(x_center=scaled_clip.w / 2, width=target_width)\n            return cropped_clip.resize((target_width, target_height))\n\n        # For other formats, use the panning logic from the source vertical video\n        clip_w, clip_h = clip.size\n        target_aspect = target_width / target_height\n\n        # ADDED 4:5 to the panning/cropping logic\n        if ratio_name in [\"16:9\", \"1:1\", \"4:5\"]:\n            # Calculate crop dimensions\n            crop_height = int(clip_w / target_aspect)\n\n            if crop_height > clip_h:\n                crop_width = int(clip_h * target_aspect)\n                crop_height = clip_h\n                x_offset = (clip_w - crop_width) // 2\n                y_offset = 0\n\n                cropped = clip.crop(x1=x_offset, y1=y_offset,\n                                  x2=x_offset + crop_width,\n                                  y2=y_offset + crop_height)\n                return cropped.resize((target_width, target_height))\n            else:\n                crop_width = clip_w\n                x_offset = 0\n\n                # Calculate movement range for panning\n                max_y_offset = clip_h - crop_height\n                center_y = max_y_offset // 2\n\n                # Determine movement direction and range\n                movement_choice = random.random()\n\n                if movement_choice < 0.4: # Pan UP\n                    start_y = center_y + random.randint(int(max_y_offset * 0.1), int(max_y_offset * 0.4))\n                    end_y = max(0, center_y - random.randint(int(max_y_offset * 0.1), int(max_y_offset * 0.4)))\n                elif movement_choice < 0.8: # Pan DOWN\n                    start_y = max(0, center_y - random.randint(int(max_y_offset * 0.1), int(max_y_offset * 0.4)))\n                    end_y = center_y + random.randint(int(max_y_offset * 0.1), int(max_y_offset * 0.4))\n                else: # Minimal movement\n                    start_y = center_y\n                    drift = random.randint(-int(max_y_offset * 0.1), int(max_y_offset * 0.1))\n                    end_y = center_y + drift\n\n                start_y = max(0, min(start_y, max_y_offset))\n                end_y = max(0, min(end_y, max_y_offset))\n\n                print(f\"  Animated crop for {ratio_name}: {start_y} ‚Üí {end_y}\")\n\n                clip_duration = clip.duration if clip.duration > 0 else 1\n\n                def crop_with_animation(get_frame, t):\n                    progress = min(1.0, t / clip_duration)\n                    current_y = int(start_y + (end_y - start_y) * progress)\n                    current_y = max(0, min(current_y, max_y_offset))\n\n                    frame = get_frame(t)\n                    cropped_frame = frame[current_y:current_y + crop_height, x_offset:x_offset + crop_width]\n                    return cropped_frame\n\n                cropped = clip.fl(crop_with_animation, apply_to=[])\n                cropped = cropped.set_duration(clip.duration)\n\n                return cropped.resize((target_width, target_height))\n\n        return clip # Fallback\n\n    except Exception as e:\n        print(f\"Error adapting clip format: {e}\")\n        import traceback\n        traceback.print_exc()\n\n        # Fallback to a simple resize in case of error\n        return clip.resize((target_width, target_height))\n\n\ndef get_subtitle_position(aspect_ratio, frame_height):\n    \"\"\"‚úÖ FIXED: Get subtitle position maintaining 1080p proportions\"\"\"\n    ratio_name = ASPECT_RATIOS[aspect_ratio][\"name\"]\n    \n    # Reference: 1080p heights and positions\n    if ratio_name == \"9:16\":\n        reference_height = 1920\n        reference_position = int(1920 * 0.65)  # 1248\n    elif ratio_name == \"4:5\":\n        reference_height = 1350\n        reference_position = int(1350 * 0.70)  # 945\n    elif ratio_name == \"16:9\":\n        reference_height = 1080\n        reference_position = int(1080 * 0.80)  # 864\n    else:  # 1:1\n        reference_height = 1080\n        reference_position = int(1080 * 0.75)  # 810\n    \n    # Scale proportionally\n    scale_factor = frame_height / reference_height\n    scaled_position = int(reference_position * scale_factor)\n    \n    return scaled_position\n\n\ndef get_title_position(aspect_ratio, frame_height):\n    \"\"\"‚úÖ Get title position - 4:5 and 1:1 moved 0.5cm higher\"\"\"\n    ratio_name = ASPECT_RATIOS[aspect_ratio][\"name\"]\n    \n    # Reference: 1080p heights and positions\n    if ratio_name == \"9:16\":\n        reference_height = 1920\n        reference_position = int(1920 * 0.115)  # 220.8\n    elif ratio_name == \"4:5\":\n        reference_height = 1350\n        # Move 0.5cm up (approx 26 pixels at 1350px height)\n        reference_position = int(1350 * 0.11) - 26   # 148.5 - 26 = 122.5\n    elif ratio_name == \"16:9\":\n        reference_height = 1080\n        reference_position = int(1080 * 0.08)   # 86.4\n    else:  # 1:1\n        reference_height = 1080\n        # Move 0.5cm up (approx 21 pixels at 1080px height)\n        reference_position = int(1080 * 0.10) - 21   # 108 - 21 = 87\n    \n    # Scale proportionally\n    scale_factor = frame_height / reference_height\n    scaled_position = int(reference_position * scale_factor)\n    \n    return scaled_position\n\n\ndef get_subtitle_font_size(aspect_ratio, frame_height):\n    \"\"\"‚úÖ Calculate subtitle font size - 9:16 increased by 5%\"\"\"\n    ratio_name = ASPECT_RATIOS[aspect_ratio][\"name\"]\n    \n    # Reference: 1080p heights for each aspect ratio\n    if ratio_name == \"9:16\":\n        reference_height = 1920  # 1080x1920 for 9:16\n        reference_font = int(60 * 1.05)  # Increased by 5%: 63\n    elif ratio_name == \"4:5\":\n        reference_height = 1350  # 1080x1350 for 4:5\n        reference_font = 60\n    elif ratio_name == \"16:9\":\n        reference_height = 1080  # 1920x1080 for 16:9\n        reference_font = 52\n    else:  # 1:1\n        reference_height = 1080  # 1080x1080 for 1:1\n        reference_font = 60\n    \n    # Scale proportionally from reference\n    scale_factor = frame_height / reference_height\n    scaled_font = int(reference_font * scale_factor)\n    \n    return scaled_font\n\n\n# ============================================================================\n# SECTION 2: Video Processing Functions (COMPLETE REPLACEMENT)\n# ============================================================================\n# Find the section \"# =========================================\" \n# with comment \"# VIDEO PROCESSING FUNCTIONS - FIXED MULTILINGUAL SUPPORT\"\n# Replace everything from that comment until the next major section\n# (usually ends before the \"def select_random_video\" or TTS/subtitle generation)\n\n# =========================================\n# VIDEO PROCESSING FUNCTIONS - FIXED MULTILINGUAL SUPPORT\n# =========================================\n\n\ndef create_title_overlay(title_text, framesize, duration=4, aspect_ratio=\"9:16 (Vertical)\"):\n    \"\"\"‚úÖ FIXED: Create 3D-style title with resolution-independent scaling\"\"\"\n    if not title_text or title_text.strip() == \"\":\n        return []\n\n    try:\n        frame_width, frame_height = framesize\n        ratio_name = ASPECT_RATIOS[aspect_ratio][\"name\"]\n\n        # Get reference height for this aspect ratio (1080p)\n        if ratio_name == \"9:16\":\n            reference_height = 1920\n        elif ratio_name == \"4:5\":\n            reference_height = 1350\n        elif ratio_name == \"16:9\":\n            reference_height = 1080\n        else:  # 1:1\n            reference_height = 1080\n        \n        # Calculate scale factor\n        scale_factor = frame_height / reference_height\n\n        # Detect script and select appropriate font\n        script = detect_script(title_text)\n\n        if script == 'cjk':\n            TITLE_FONT_URL = \"https://github.com/notofonts/noto-cjk/raw/main/Sans/OTF/SimplifiedChinese/NotoSansCJKsc-Bold.otf\"\n            TITLE_FONT_PATH = \"/tmp/NotoSansCJK-Bold-Title.otf\"\n        elif script == 'devanagari':\n            TITLE_FONT_URL = \"https://github.com/notofonts/notofonts.github.io/raw/main/fonts/NotoSansDevanagari/hinted/ttf/NotoSansDevanagari-Bold.ttf\"\n            TITLE_FONT_PATH = \"/tmp/NotoSansDevanagari-Bold-Title.ttf\"\n        elif script == 'arabic':\n            TITLE_FONT_URL = \"https://github.com/notofonts/notofonts.github.io/raw/main/fonts/NotoSansArabic/hinted/ttf/NotoSansArabic-Bold.ttf\"\n            TITLE_FONT_PATH = \"/tmp/NotoSansArabic-Bold-Title.ttf\"\n        else:\n            TITLE_FONT_URL = \"https://github.com/notofonts/notofonts.github.io/raw/main/fonts/NotoSans/hinted/ttf/NotoSans-Bold.ttf\"\n            TITLE_FONT_PATH = \"/tmp/NotoSans-Bold-Title.ttf\"\n\n        # Download font if needed\n        title_font_path = None\n        if not os.path.exists(TITLE_FONT_PATH):\n            try:\n                print(f\"üì• Downloading {script} font for title...\")\n                urllib.request.urlretrieve(TITLE_FONT_URL, TITLE_FONT_PATH)\n                print(f\"‚úÖ Title font ready for {script}\")\n            except Exception as e:\n                print(f\"‚ö†Ô∏è Font download failed: {e}\")\n\n        if os.path.exists(TITLE_FONT_PATH):\n            title_font_path = TITLE_FONT_PATH\n\n        base_margin = get_title_position(aspect_ratio, frame_height)\n\n        # ‚úÖ FIXED: Scale adjustment proportionally\n        POSITION_ADJUSTMENT = int((reference_height * 0.035) * scale_factor)\n        TOP_MARGIN = int(base_margin * 0.65) + POSITION_ADJUSTMENT\n\n        # ‚úÖ Font size scaled from 1080p reference - 4:5 and 1:1 reduced by 5%\n        if ratio_name == \"9:16\":\n            reference_font = int(1920 * 0.0413712)  # ~79\n        elif ratio_name in [\"4:5\", \"1:1\"]:\n            # Reduced by 5%\n            reference_font = int((1350 * 0.0572) * 0.95) if ratio_name == \"4:5\" else int((1080 * 0.0572) * 0.95)\n        else:  # 16:9\n            reference_font = int(1080 * 0.052)\n        \n        # Scale proportionally\n        FONT_SIZE = int(reference_font * scale_factor)\n\n        BLACK = (0, 0, 0)\n        WHITE = (255, 255, 255)\n\n        # ‚úÖ FIXED: Scale decorative elements from reference\n        EXTRUDE_DEPTH = max(3, int((reference_height * 0.007) * scale_factor))\n        GLOW_RADIUS = max(6, int((reference_height * 0.012) * scale_factor))\n        STROKE_WIDTH = max(2, int((reference_height * 0.004) * scale_factor))\n\n        MAX_LINES = 4\n        LINE_SPACING = max(3, int((reference_height * 0.006) * scale_factor))\n\n        def load_font(size):\n            try:\n                if title_font_path and os.path.exists(title_font_path):\n                    return ImageFont.truetype(title_font_path, size)\n            except Exception as e:\n                print(f\"‚ö†Ô∏è Font load failed: {e}\")\n\n            system_fonts = [\n                \"/usr/share/fonts/truetype/noto/NotoSans-Bold.ttf\",\n                \"/usr/share/fonts/truetype/noto/NotoSansDevanagari-Bold.ttf\",\n                \"/usr/share/fonts/truetype/noto/NotoSansCJK-Bold.ttc\",\n                \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\",\n                \"/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf\",\n            ]\n\n            for font_path in system_fonts:\n                try:\n                    if os.path.exists(font_path): return ImageFont.truetype(font_path, size)\n                except: continue\n\n            print(\"‚ö†Ô∏è Using default font\")\n            return ImageFont.load_default()\n\n        font_obj = load_font(FONT_SIZE)\n        temp_img = Image.new(\"RGBA\", (frame_width, frame_height), (0,0,0,0))\n        temp_draw = ImageDraw.Draw(temp_img)\n\n        def measure_text(text, font):\n            try:\n                bbox = temp_draw.textbbox((0,0), text, font=font, stroke_width=STROKE_WIDTH)\n                return bbox[2]-bbox[0], bbox[3]-bbox[1]\n            except:\n                return 100, 50\n\n        def wrap_text_fixed_size(text, font, max_width):\n            is_cjk = is_cjk_script(text)\n            if not is_cjk and detect_script(text) == 'latin':\n                try: text = text.upper()\n                except: pass\n\n            if is_cjk:\n                lines, current = [], \"\"\n                for char in text:\n                    w, _ = measure_text(current + char, font)\n                    if w <= max_width: current += char\n                    else:\n                        if current: lines.append(current)\n                        current = char\n                if current: lines.append(current)\n                return lines\n            else:\n                words, lines, current = text.split(), [], []\n                for word in words:\n                    w, _ = measure_text(\" \".join(current + [word]), font)\n                    if w <= max_width: current.append(word)\n                    else:\n                        if current: lines.append(\" \".join(current))\n                        current = [word] if word else []\n                if current: lines.append(\" \".join(current))\n                return lines\n\n        max_width = frame_width * 0.88\n        lines = wrap_text_fixed_size(title_text, font_obj, max_width)\n\n        if len(lines) > MAX_LINES: lines = lines[:MAX_LINES]\n\n        line_heights = [measure_text(line, font_obj)[1] for line in lines]\n        y_start = TOP_MARGIN\n        x_center = frame_width // 2\n        base = Image.new(\"RGBA\", (frame_width, frame_height), (0, 0, 0, 0))\n\n        background_layer = Image.new(\"RGBA\", (frame_width, frame_height), (0, 0, 0, 0))\n        bg_draw = ImageDraw.Draw(background_layer)\n        y_cursor = y_start\n\n        padding = int(FONT_SIZE * 0.25)\n        radius = int(FONT_SIZE * 0.3)\n\n        for i, line in enumerate(lines):\n            line_width, _ = measure_text(line, font_obj)\n            x = x_center - line_width // 2\n            y = y_cursor\n\n            bbox = bg_draw.textbbox((x, y), line, font=font_obj, stroke_width=STROKE_WIDTH)\n\n            bg_draw.rounded_rectangle(\n                [(bbox[0] - padding, bbox[1] - padding), (bbox[2] + padding, bbox[3] + padding)],\n                radius=radius,\n                fill=(0, 0, 0, 112)\n            )\n\n            y_cursor += line_heights[i] + LINE_SPACING\n\n        base = Image.alpha_composite(base, background_layer)\n\n        def draw_text_lines(target_draw, lines, x_center, y_start, font, **kwargs):\n            y = y_start\n            for i, line in enumerate(lines):\n                w, _ = measure_text(line, font)\n                x = x_center - w // 2\n                target_draw.text((x, y), line, font=font, **kwargs)\n                y += line_heights[i] + LINE_SPACING\n\n        extrude_layer = Image.new(\"RGBA\", (frame_width, frame_height), (0, 0, 0, 0))\n        ext_draw = ImageDraw.Draw(extrude_layer)\n        for i in range(EXTRUDE_DEPTH, 0, -1):\n            alpha = int(255 * (i / EXTRUDE_DEPTH) * 0.3)\n            draw_text_lines(ext_draw, lines, x_center + i, y_start + i // 2, font_obj, fill=(0, 0, 0, alpha))\n        extrude_layer = extrude_layer.filter(ImageFilter.GaussianBlur(1))\n        base = Image.alpha_composite(base, extrude_layer)\n\n        glow_layer = Image.new(\"RGBA\", (frame_width, frame_height), (0, 0, 0, 0))\n        glow_draw = ImageDraw.Draw(glow_layer)\n        draw_text_lines(glow_draw, lines, x_center, y_start, font_obj, fill=(0, 0, 0, 100))\n        glow_layer = glow_layer.filter(ImageFilter.GaussianBlur(GLOW_RADIUS))\n        base = Image.alpha_composite(base, glow_layer)\n\n        shadow_layer = Image.new(\"RGBA\", (frame_width, frame_height), (0, 0, 0, 0))\n        shadow_draw = ImageDraw.Draw(shadow_layer)\n        draw_text_lines(shadow_draw, lines, x_center + 2, y_start + 2, font_obj, fill=(20, 20, 20, 180))\n        base = Image.alpha_composite(base, shadow_layer)\n\n        final_draw = ImageDraw.Draw(base)\n        draw_text_lines(final_draw, lines, x_center, y_start, font_obj, fill=WHITE, stroke_width=STROKE_WIDTH, stroke_fill=BLACK)\n\n        img_array = np.array(base)\n        title_clip = ImageClip(img_array, duration=duration)\n        return [title_clip]\n    except Exception as e:\n        print(f\"Error creating title: {e}\")\n        import traceback\n        traceback.print_exc()\n        return []\n\n\n# ============================================================================\n# SECTION 3: Caption Creation (Part of Subtitle Functions)\n# ============================================================================\n# Find the \"create_caption\" function and replace it completely with this:\n\ndef create_caption(textJSON, framesize, font=\"Helvetica-Bold\", fontsize=14, color='white', aspect_ratio=\"9:16 (Vertical)\"):\n    \"\"\"‚úÖ FIXED: Create captions with word-by-word highlighting and resolution-independent scaling\"\"\"\n    try:\n        full_duration = textJSON.get('end', 0) - textJSON.get('start', 0)\n        if full_duration <= 0:\n            return []\n\n        word_clips = []\n        xy_textclips_positions = []\n\n        frame_width = framesize[0]\n        frame_height = framesize[1]\n        \n        subtitle_fontsize = get_subtitle_font_size(aspect_ratio, frame_height)\n        \n        ratio_name = ASPECT_RATIOS[aspect_ratio][\"name\"]\n        if ratio_name == \"9:16\":\n            max_line_width = frame_width * 0.85\n        elif ratio_name == \"16:9\":\n            max_line_width = frame_width * 0.88\n        else:\n            max_line_width = frame_width * 0.85\n\n        # Get full text to check if CJK\n        full_text = textJSON.get('word', '')\n        is_cjk = is_cjk_script(full_text)\n\n        lines = []\n        current_line = []\n        current_line_width = 0\n\n        for wordJSON in textJSON.get('textcontents', []):\n            word_text = wordJSON.get('word', '').strip()\n            \n            # Don't uppercase non-Latin scripts\n            if is_cjk or detect_script(word_text) != 'latin':\n                word_display = word_text\n            else:\n                try:\n                    word_display = word_text.upper()\n                except:\n                    word_display = word_text\n            \n            temp_word = get_cached_text_clip(word_display, font, subtitle_fontsize, color)\n            \n            # Only add space for non-CJK languages\n            if not is_cjk:\n                temp_space = get_cached_text_clip(\" \", font, subtitle_fontsize, color)\n                space_width, _ = temp_space.size\n            else:\n                space_width = 0\n\n            word_width, word_height = temp_word.size\n\n            # Check if we need to break line\n            if current_line_width + word_width + space_width > max_line_width and current_line:\n                lines.append({\n                    'words': current_line.copy(),\n                    'width': current_line_width - (space_width if not is_cjk and current_line else 0),\n                    'height': word_height\n                })\n                current_line = [wordJSON]\n                current_line_width = word_width + space_width\n            else:\n                current_line.append(wordJSON)\n                current_line_width += word_width + space_width\n\n        if current_line:\n            word_display = current_line[0].get('word', '').strip()\n            if is_cjk or detect_script(word_display) != 'latin':\n                pass\n            else:\n                try:\n                    word_display = word_display.upper()\n                except:\n                    pass\n            temp_word = get_cached_text_clip(word_display, font, subtitle_fontsize, color)\n            _, word_height = temp_word.size\n            lines.append({\n                'words': current_line,\n                'width': current_line_width - (space_width if not is_cjk else 0),\n                'height': word_height\n            })\n\n        total_text_height = sum(line['height'] for line in lines) + (len(lines) - 1) * 3\n        subtitle_y_position = get_subtitle_position(aspect_ratio, frame_height)\n        current_y = subtitle_y_position\n\n        # Get reference height for scaling\n        if ratio_name == \"9:16\":\n            reference_height = 1920\n        elif ratio_name == \"4:5\":\n            reference_height = 1350\n        elif ratio_name == \"16:9\":\n            reference_height = 1080\n        else:\n            reference_height = 1080\n        \n        scale_factor = frame_height / reference_height\n\n        if lines:\n            # ‚úÖ FIXED: Scale padding proportionally from reference\n            reference_padding = 25\n            reference_height_extra = 15\n            shadow_padding = max(int(reference_padding * scale_factor), int(subtitle_fontsize * 0.6))\n            shadow_height_extra = max(int(reference_height_extra * scale_factor), int(subtitle_fontsize * 0.35))\n            total_subtitle_width = max(line['width'] for line in lines)\n\n            bg_width = int(total_subtitle_width + shadow_padding * 2)\n            bg_height = int(total_text_height + shadow_height_extra * 2)\n\n            img = Image.new('RGBA', (bg_width, bg_height), (0, 0, 0, 0))\n            draw = ImageDraw.Draw(img)\n\n            draw.rounded_rectangle(\n                [(0, 0), (bg_width-1, bg_height-1)],\n                radius=15,\n                fill=(0, 0, 0, 128)\n            )\n\n            img_array = np.array(img)\n            shadow_bg = ImageClip(img_array, duration=full_duration).set_start(textJSON.get('start', 0))\n\n            shadow_x = (frame_width - total_subtitle_width) / 2 - shadow_padding\n            shadow_y = subtitle_y_position - shadow_height_extra\n            shadow_bg = shadow_bg.set_position((shadow_x, shadow_y))\n            word_clips.append(shadow_bg)\n\n        for line in lines:\n            line_words = line['words']\n            word_dimensions = []\n\n            for wordJSON in line_words:\n                word_text = wordJSON.get('word', '').strip()\n                \n                if is_cjk or detect_script(word_text) != 'latin':\n                    word_display = word_text\n                else:\n                    try:\n                        word_display = word_text.upper()\n                    except:\n                        word_display = word_text\n                \n                temp_word = get_cached_text_clip(word_display, font, subtitle_fontsize, color)\n                word_width, word_height = temp_word.size\n                \n                if not is_cjk:\n                    temp_space = get_cached_text_clip(\" \", font, subtitle_fontsize, color)\n                    space_width, _ = temp_space.size\n                else:\n                    space_width = 0\n\n                word_dimensions.append({\n                    'word_data': wordJSON,\n                    'word_width': word_width,\n                    'word_height': word_height,\n                    'space_width': space_width,\n                    'word_display': word_display\n                })\n\n            line_start_x = (frame_width - line['width']) / 2\n            current_x = line_start_x\n\n            for word_dim in word_dimensions:\n                wordJSON = word_dim['word_data']\n                word_width = word_dim['word_width']\n                word_height = word_dim['word_height']\n                space_width = word_dim['space_width']\n                word_display = word_dim['word_display']\n\n                shadow_text = get_cached_text_clip(word_display, font, subtitle_fontsize, 'black')\n                shadow_text = shadow_text.set_start(textJSON.get('start', 0)).set_duration(full_duration)\n                shadow_text = shadow_text.set_position((current_x + 1, current_y + 1)).set_opacity(0.3)\n                word_clips.append(shadow_text)\n\n                word_clip = get_cached_text_clip(word_display, font, subtitle_fontsize, color)\n                word_clip = word_clip.set_start(textJSON.get('start', 0)).set_duration(full_duration)\n                word_clip = word_clip.set_position((current_x, current_y))\n\n                # Only add space clip for non-CJK\n                if not is_cjk and space_width > 0:\n                    space_clip = get_cached_text_clip(\" \", font, subtitle_fontsize, color)\n                    space_clip = space_clip.set_start(textJSON.get('start', 0)).set_duration(full_duration)\n                    space_clip = space_clip.set_position((current_x + word_width, current_y))\n                    word_clips.append(space_clip)\n\n                word_duration = wordJSON.get('end', 0) - wordJSON.get('start', 0)\n                if word_duration <= 0:\n                    word_duration = 0.1\n\n                xy_textclips_positions.append({\n                    \"x_pos\": current_x,\n                    \"y_pos\": current_y,\n                    \"width\": word_width,\n                    \"height\": word_height,\n                    \"word\": word_display,\n                    \"start\": wordJSON.get('start', 0),\n                    \"end\": wordJSON.get('end', 0),\n                    \"duration\": word_duration\n                })\n\n                word_clips.append(word_clip)\n                current_x += word_width + space_width\n\n            current_y += line['height'] + 3\n\n        for highlight_word in xy_textclips_positions:\n            if highlight_word['duration'] <= 0:\n                continue\n\n            # ‚úÖ FIXED: Scale highlight box dimensions proportionally\n            reference_width_padding = 16\n            reference_height_padding = 8\n            bg_width = int(highlight_word['width'] + max(int(reference_width_padding * scale_factor), int(subtitle_fontsize * 0.38)))\n            bg_height = int(highlight_word['height'] + max(int(reference_height_padding * scale_factor), int(subtitle_fontsize * 0.19)))\n\n            img = Image.new('RGBA', (bg_width, bg_height), (0, 0, 0, 0))\n            draw = ImageDraw.Draw(img)\n\n            draw.rounded_rectangle(\n                [(0, 0), (bg_width-1, bg_height-1)],\n                radius=8,\n                fill=(147, 0, 211, 180)\n            )\n\n            img_array = np.array(img)\n            bg_clip = ImageClip(img_array, duration=highlight_word['duration'])\n            bg_clip = bg_clip.set_start(highlight_word['start'])\n\n            # ‚úÖ FIXED: Scale highlight position offsets proportionally\n            bg_x = highlight_word['x_pos'] - max(int(8 * scale_factor), int(subtitle_fontsize * 0.19))\n            bg_y = highlight_word['y_pos'] - max(int(4 * scale_factor), int(subtitle_fontsize * 0.095))\n            bg_clip = bg_clip.set_position((bg_x, bg_y))\n\n            shadow_highlight = get_cached_text_clip(highlight_word['word'], font, subtitle_fontsize, 'black')\n            shadow_highlight = shadow_highlight.set_start(highlight_word['start']).set_duration(highlight_word['duration'])\n            shadow_highlight = shadow_highlight.set_position((highlight_word['x_pos'] + 1, highlight_word['y_pos'] + 1)).set_opacity(0.4)\n\n            word_clip_highlight = get_cached_text_clip(highlight_word['word'], font, subtitle_fontsize, 'white')\n            word_clip_highlight = word_clip_highlight.set_start(highlight_word['start']).set_duration(highlight_word['duration'])\n            word_clip_highlight = word_clip_highlight.set_position((highlight_word['x_pos'], highlight_word['y_pos']))\n\n            word_clips.append(bg_clip)\n            word_clips.append(shadow_highlight)\n            word_clips.append(word_clip_highlight)\n\n        return word_clips\n        \n    except Exception as e:\n        print(f\"Error creating caption: {e}\")\n        import traceback\n        traceback.print_exc()\n        return []","metadata":{"_uuid":"bfbb87a9-cebc-4fcc-bd94-870c428960e2","_cell_guid":"90cee886-98b9-47da-babc-72af132003c5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Part 4: State Persistence Functions**","metadata":{"_uuid":"f8b64c29-d3b7-42d3-91bc-b3bfff44bda6","_cell_guid":"c5c87cc4-eedd-47e8-bf71-d03580d3886b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# State Persistence Functions\ndef save_ui_state(text_input=\"\", voice_selection=\"Puck\", title_text=\"\", duration=2, quality=\"High\", auto_title=True):\n    \"\"\"Save UI state to file\"\"\"\n    try:\n        state = {\n            'text_input': text_input,\n            'voice_selection': voice_selection,\n            'title_text': title_text,\n            'duration': duration,\n            'quality': quality,\n            'auto_title': auto_title,\n            'timestamp': datetime.now().isoformat()\n        }\n        with open(STATE_FILE, 'w') as f:\n            json.dump(state, f, indent=2)\n    except Exception as e:\n        print(f\"Error saving state: {e}\")\n\ndef load_ui_state():\n    \"\"\"Load UI state from file\"\"\"\n    try:\n        if os.path.exists(STATE_FILE):\n            with open(STATE_FILE, 'r') as f:\n                state = json.load(f)\n                return state\n    except Exception as e:\n        print(f\"Error loading state: {e}\")\n    return {}","metadata":{"_uuid":"cdc64134-dc44-4862-9d45-db8471a534f3","_cell_guid":"2d5eec1e-4504-41b8-b815-8ac3d3dfdcb8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Part 5: API Key Management**","metadata":{"_uuid":"7cedaa8e-bf02-499c-be6c-e8225acf6f13","_cell_guid":"411314ba-f740-4194-b390-e1375b927611","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Part 5: API Key Management with Updated Keys\n\nAPI_KEYS = [\n    'AIzaSyBWYWNkIt8Q7nl7I-JDj9ozaVwOAFf7WsA',\n    'AIzaSyB4Y_Z8bc82VN15pGes-a049ZNcjTsJTFs',\n    'AIzaSyD3vGJyJtdSKuaxbb4AZVosyJ76ult21d8',\n    'AIzaSyAbmN08A4l61-q1mYjK3DQe29BKcSYmov8',\n    'AIzaSyAD8-aEvVIvkBwQFUMugb9XgVDBUQR-zfk',\n    'AIzaSyD-nf3OHLbI5R23f7VLVLO1FHTWM6OWwCs',\n    'AIzaSyBjYlIv84CNzpudzYyl6ANCz-2xRtSw5Dc',\n    'AIzaSyCLjFGChLdvNSBoCVKbTAtR4zNTegeI19U',\n    'AIzaSyD5IB7uqfyAp9XbN7GrZb_ykofO44AFIWw',\n    'AIzaSyAuLu3EU3o_bp4GsHKKQuvE-u02EXEi308',\n    'AIzaSyDcwUdktdj5J1JsVn8pLY4aog2S-2hE1j4',\n    'AIzaSyCNJdzUaErIF4CkHhd_W3cNAhU7qqWgWLI',\n    'AIzaSyA94-jrtNUK1Rs9DWxE4YH7cAvpo4oGu5k',\n    'AIzaSyBiR58evdCtCGAtZiOvIiwAKtc6P-K6d0o',\n    'AIzaSyAC3au8LAdnk_-yrzKTZ9EfDUUypJc2K_0',\n    'AIzaSyANdNVOWRlRKubxa7w0lX21MFztQtHirbM',\n    'AIzaSyCqf1kobLM4Xo1WDkl49UJpXvJp3g1g6RE',\n    'AIzaSyAclybUHEwGic8nIRsIgV976UQNmxCAqSQ',\n    'AIzaSyCASH5DEm2l8JwfFWJw8gMtYgR8fjip2sA',\n    'AIzaSyBN0V0v5IetKuEFaKTB9vfyBE0oVzZDVWg'\n]\n\n# ‚úÖ Start from random position to distribute load\nimport random\ncurrent_api_key_index = random.randint(0, len(API_KEYS) - 1)\n\ndef get_next_api_key():\n    \"\"\"Get next API key in rotation (continues in order after random start)\"\"\"\n    global current_api_key_index\n    api_key = API_KEYS[current_api_key_index]\n    print(f\"üîë Using API key #{current_api_key_index + 1} of {len(API_KEYS)}\")\n    current_api_key_index = (current_api_key_index + 1) % len(API_KEYS)  # Wrap around\n    return api_key\n\ndef reset_api_key_rotation():\n    \"\"\"Reset API key rotation to random start position\"\"\"\n    global current_api_key_index\n    current_api_key_index = random.randint(0, len(API_KEYS) - 1)\n    print(f\"üîÑ API key rotation reset to random position: #{current_api_key_index + 1}/{len(API_KEYS)}\")\n\ndef load_api_key():\n    \"\"\"Load API key from file or use random key\"\"\"\n    try:\n        if os.path.exists(API_KEY_FILE):\n            with open(API_KEY_FILE, 'r') as f:\n                key = f.read().strip()\n                if key:\n                    return key\n    except:\n        pass\n    # Return current position in rotation\n    return API_KEYS[current_api_key_index]\n\ndef save_api_key(key):\n    \"\"\"Save API key to file\"\"\"\n    try:\n        with open(API_KEY_FILE, 'w') as f:\n            f.write(key.strip())\n        os.environ['GOOGLE_API_KEY'] = key.strip()\n        return \"API key saved successfully\"\n    except Exception as e:\n        return f\"Error saving API key: {e}\"\n\ndef get_current_api_key():\n    \"\"\"Get current API key (masked)\"\"\"\n    key = load_api_key()\n    if len(key) > 8:\n        return f\"{key[:4]}...{key[-4:]}\"\n    return \"****\"\n\ndef get_api_rotation_status():\n    \"\"\"Get current API rotation status\"\"\"\n    return f\"Key {current_api_key_index + 1}/{len(API_KEYS)}\"\n\n# Set the API key in environment (random start)\nos.environ['GOOGLE_API_KEY'] = load_api_key()\nprint(f\"üé≤ Initialized with random API key position: {current_api_key_index + 1}/{len(API_KEYS)}\")\nprint(f\"üìä Total API keys available: {len(API_KEYS)}\")","metadata":{"_uuid":"a5398541-bddc-4f6e-bd26-4a6af2649120","_cell_guid":"98df494b-621a-46fe-8a20-5e0b593f7be2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Part 6: Folder Scanning Functions**","metadata":{"_uuid":"68ee8859-2c53-43ee-bbba-37ad5e9c5d74","_cell_guid":"d5b80ed7-bb89-4b01-97c5-2b779ccebc70","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Folder Scanning Functions\ndef scan_available_folders():\n    \"\"\"Scan for available video and music folders\"\"\"\n    try:\n        input_path = '/kaggle/input'\n        if not os.path.exists(input_path):\n            return [], []\n        \n        video_folders = []\n        music_folders = []\n        \n        for folder_name in os.listdir(input_path):\n            folder_path = os.path.join(input_path, folder_name)\n            if os.path.isdir(folder_path):\n                files = os.listdir(folder_path)\n                video_extensions = ('.mp4', '.avi', '.mkv', '.mov', '.MP4', '.AVI', '.MKV', '.MOV')\n                audio_extensions = ('.mp3', '.wav', '.m4a', '.aac', '.ogg', '.flac', '.MP3', '.WAV', '.M4A', '.AAC')\n                \n                has_videos = any(f.endswith(video_extensions) for f in files)\n                has_audio = any(f.endswith(audio_extensions) for f in files)\n                \n                if has_videos:\n                    video_count = sum(1 for f in files if f.endswith(video_extensions))\n                    video_folders.append({\n                        'path': folder_path,\n                        'name': folder_name,\n                        'count': video_count,\n                        'label': f\"{folder_name} ({video_count} videos)\"\n                    })\n                \n                if has_audio:\n                    audio_count = sum(1 for f in files if f.endswith(audio_extensions))\n                    music_folders.append({\n                        'path': folder_path,\n                        'name': folder_name,\n                        'count': audio_count,\n                        'label': f\"{folder_name} ({audio_count} files)\"\n                    })\n        \n        return video_folders, music_folders\n    except Exception as e:\n        print(f\"Error scanning folders: {e}\")\n        return [], []\n\ndef get_folder_choices(folder_type='video'):\n    \"\"\"Get dropdown choices for folders\"\"\"\n    video_folders, music_folders = scan_available_folders()\n    \n    if folder_type == 'video':\n        if not video_folders:\n            return [(\"No video folders found\", \"\")]\n        return [(f['label'], f['path']) for f in video_folders]\n    else:\n        choices = [(\"Random (Auto)\", \"\")]\n        if music_folders:\n            choices.extend([(f['label'], f['path']) for f in music_folders])\n        return choices\n\ndef get_random_music_file(music_folder_path):\n    \"\"\"Select a random music file from the folder\"\"\"\n    try:\n        if not music_folder_path or not os.path.exists(music_folder_path):\n            return None\n        \n        audio_extensions = ('.mp3', '.wav', '.m4a', '.aac', '.ogg', '.flac', '.MP3', '.WAV', '.M4A', '.AAC')\n        music_files = [f for f in os.listdir(music_folder_path) if f.endswith(audio_extensions)]\n        \n        if not music_files:\n            return None\n        \n        # üé≤ Re-seed for truly random music selection\n        import time\n        random.seed(time.time() + os.getpid() + random.randint(0, 999999))\n        selected_file = random.choice(music_files)\n        full_path = os.path.join(music_folder_path, selected_file)\n        print(f\"Selected background music: {selected_file}\")\n        return full_path\n    except Exception as e:\n        print(f\"Error selecting random music: {e}\")\n        return None\n\ndef get_default_music_folder():\n    \"\"\"Get default background music folder\"\"\"\n    video_folders, music_folders = scan_available_folders()\n    if music_folders:\n        return music_folders[0]['path']\n    return \"\"\n\n# NEW FUNCTION: Get dataset list for Telegram bot\ndef get_dataset_list():\n    \"\"\"Get formatted list of video datasets for selection\"\"\"\n    video_folders, _ = scan_available_folders()\n    \n    if not video_folders:\n        return None\n    \n    return video_folders\n\ndef get_dataset_by_name(dataset_name):\n    \"\"\"Get dataset path by name\"\"\"\n    video_folders, _ = scan_available_folders()\n    \n    for folder in video_folders:\n        if folder['name'] == dataset_name:\n            return folder['path']\n    \n    return None\n\nprint(\"‚úÖ Folder scanning functions loaded with dataset selection support\")","metadata":{"_uuid":"e251e4e0-46fe-46ea-bc87-a71ea2f251c9","_cell_guid":"a74e4d01-bf11-402d-a1ac-6aaab6bb479e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Part 7: History Management Functions**","metadata":{"_uuid":"981d18d5-8ae2-4c3c-90ac-a18aa93a1430","_cell_guid":"d5d161f3-1a58-490f-b471-592b3f624490","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# History Management Functions\ndef scan_exports_folder():\n    \"\"\"Scan exports folder and list all video files\"\"\"\n    try:\n        if not os.path.exists(OUTPUT_PATH):\n            os.makedirs(OUTPUT_PATH, exist_ok=True)\n            return []\n        \n        video_files = []\n        for filename in os.listdir(OUTPUT_PATH):\n            if filename.endswith('.mp4'):\n                filepath = os.path.join(OUTPUT_PATH, filename)\n                if os.path.exists(filepath):\n                    try:\n                        file_stat = os.stat(filepath)\n                        video_files.append({\n                            'path': filepath,\n                            'filename': filename,\n                            'timestamp': datetime.fromtimestamp(file_stat.st_mtime).isoformat(),\n                            'size_mb': round(file_stat.st_size / (1024 * 1024), 2)\n                        })\n                    except Exception as e:\n                        print(f\"Error reading {filename}: {e}\")\n                        continue\n        \n        video_files.sort(key=lambda x: x['timestamp'], reverse=True)\n        return video_files\n    \n    except Exception as e:\n        print(f\"Error scanning exports folder: {e}\")\n        return []\n\ndef save_to_history(video_path, metadata):\n    \"\"\"Save video metadata to history file\"\"\"\n    try:\n        metadata_map = {}\n        if os.path.exists(HISTORY_FILE):\n            try:\n                with open(HISTORY_FILE, 'r') as f:\n                    history_data = json.load(f)\n                    for item in history_data:\n                        metadata_map[item['filename']] = item.get('metadata', {})\n            except:\n                pass\n        \n        filename = os.path.basename(video_path)\n        video_info = {\n            'path': video_path,\n            'filename': filename,\n            'timestamp': datetime.now().isoformat(),\n            'size_mb': round(os.path.getsize(video_path) / (1024 * 1024), 2),\n            'metadata': metadata\n        }\n        \n        metadata_map[filename] = metadata\n        \n        all_videos = scan_exports_folder()\n        for video in all_videos:\n            if video['filename'] in metadata_map:\n                video['metadata'] = metadata_map[video['filename']]\n        \n        with open(HISTORY_FILE, 'w') as f:\n            json.dump(all_videos, f, indent=2)\n        \n        print(f\"Saved to history: {filename}\")\n        return True\n    except Exception as e:\n        print(f\"Error saving to history: {e}\")\n        return False\n\ndef load_history():\n    \"\"\"Load video history\"\"\"\n    try:\n        videos = scan_exports_folder()\n        \n        metadata_map = {}\n        if os.path.exists(HISTORY_FILE):\n            try:\n                with open(HISTORY_FILE, 'r') as f:\n                    history_data = json.load(f)\n                    for item in history_data:\n                        metadata_map[item['filename']] = item.get('metadata', {})\n            except:\n                pass\n        \n        for video in videos:\n            if video['filename'] in metadata_map:\n                video['metadata'] = metadata_map[video['filename']]\n        \n        return videos\n    except Exception as e:\n        print(f\"Error loading history: {e}\")\n        return []\n\ndef get_history_choices():\n    \"\"\"Get video choices for dropdown\"\"\"\n    history = load_history()\n    if not history:\n        return [(\"No videos in exports folder\", \"\")]\n    \n    choices = []\n    for video in history:\n        try:\n            timestamp = datetime.fromisoformat(video['timestamp']).strftime(\"%m/%d %H:%M\")\n            size_mb = video.get('size_mb', 0)\n            metadata = video.get('metadata', {})\n            duration = metadata.get('duration', 'N/A')\n            aspect_ratio = metadata.get('aspect_ratio', 'N/A')\n            label = f\"{video['filename']} - {timestamp} ({size_mb:.1f}MB) - {duration}s - {aspect_ratio}\"\n            choices.append((label, video['path']))\n        except:\n            choices.append((video['filename'], video['path']))\n    \n    return choices\n\ndef load_selected_video(video_path):\n    \"\"\"Load selected video for viewing\"\"\"\n    if video_path and os.path.exists(video_path):\n        return video_path, f\"Loaded: {os.path.basename(video_path)}\"\n    return None, \"Select a video from history\"\n\ndef delete_video_from_history(video_path):\n    \"\"\"Delete a video file and its entry from history\"\"\"\n    try:\n        if not video_path or not os.path.exists(video_path):\n            return False, \"Video file not found\"\n            \n        # Remove video file\n        os.remove(video_path)\n        print(f\"Deleted video: {os.path.basename(video_path)}\")\n        \n        # Update history\n        videos = load_history()\n        updated_videos = [v for v in videos if v['path'] != video_path]\n        \n        with open(HISTORY_FILE, 'w') as f:\n            json.dump(updated_videos, f, indent=2)\n            \n        return True, \"Video deleted successfully\"\n    except Exception as e:\n        print(f\"Error deleting video: {e}\")\n        return False, f\"Error deleting video: {str(e)}\"\n\ndef clear_all_history():\n    \"\"\"Clear all videos from history and exports\"\"\"\n    try:\n        # Remove all video files\n        import glob\n        for file in glob.glob(os.path.join(OUTPUT_PATH, '*.mp4')):\n            os.remove(file)\n        \n        # Clear history file\n        with open(HISTORY_FILE, 'w') as f:\n            json.dump([], f)\n            \n        return True, \"All history cleared successfully\"\n    except Exception as e:\n        print(f\"Error clearing history: {e}\")\n        return False, f\"Error clearing history: {str(e)}\"\n\ndef get_video_details(video_path):\n    \"\"\"Get detailed information about a video\"\"\"\n    try:\n        if not video_path or not os.path.exists(video_path):\n            return \"No video selected\"\n            \n        filename = os.path.basename(video_path)\n        file_size = round(os.path.getsize(video_path) / (1024 * 1024), 2)\n        \n        # Get metadata from history\n        videos = load_history()\n        metadata = {}\n        for video in videos:\n            if video['path'] == video_path:\n                metadata = video.get('metadata', {})\n                break\n        \n        # Format details\n        details = f\"Filename: {filename}\\n\"\n        details += f\"Size: {file_size} MB\\n\"\n        \n        if metadata:\n            if 'duration' in metadata:\n                details += f\"Duration: {metadata['duration']} seconds\\n\"\n            if 'aspect_ratio' in metadata:\n                details += f\"Aspect Ratio: {metadata['aspect_ratio']}\\n\"\n            if 'quality' in metadata:\n                details += f\"Quality: {metadata['quality']}\\n\"\n            if 'audio_type' in metadata:\n                details += f\"Audio: {metadata['audio_type']}\\n\"\n            if 'title' in metadata:\n                details += f\"Title: {metadata['title']}\\n\"\n            if 'subtitle_lines' in metadata:\n                details += f\"Subtitle Lines: {metadata['subtitle_lines']}\\n\"\n        \n        return details\n    except Exception as e:\n        return f\"Error getting video details: {str(e)}\"","metadata":{"_uuid":"d72fdbe6-f1ae-489c-8a32-0626fe3a8d42","_cell_guid":"10bab986-9483-4fd2-8a7e-504a18a403ad","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Part 8: Status Functions**","metadata":{"_uuid":"cdb943c2-c50f-408f-9252-e744b8f9c533","_cell_guid":"48319984-d0cc-4048-b103-37935d8ea781","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Status Functions\ndef save_status(status, progress_percent, output_path=None, error=None):\n    \"\"\"Save generation status to disk\"\"\"\n    try:\n        status_data = {\n            'status': status,\n            'progress': progress_percent,\n            'output_path': output_path,\n            'error': error,\n            'timestamp': datetime.now().isoformat()\n        }\n        with open(STATUS_FILE, 'w') as f:\n            json.dump(status_data, f)\n        print(f\"Status: {status} ({progress_percent}%)\")\n    except Exception as e:\n        print(f\"Error saving status: {e}\")\n\ndef load_status():\n    \"\"\"Load generation status from disk\"\"\"\n    try:\n        if os.path.exists(STATUS_FILE):\n            with open(STATUS_FILE, 'r') as f:\n                return json.load(f)\n    except Exception as e:\n        print(f\"Error loading status: {e}\")\n    return None\n\ndef check_generation_status():\n    \"\"\"Check if there's an ongoing or completed generation\"\"\"\n    status = load_status()\n    if not status:\n        return None, \"No active generation\"\n    \n    progress = status.get('progress', 0)\n    status_text = status.get('status', 'Unknown')\n    output_path = status.get('output_path')\n    error = status.get('error')\n    \n    if error:\n        return None, f\"Failed: {error}\"\n    \n    if output_path and os.path.exists(output_path):\n        file_size = os.path.getsize(output_path) / (1024 * 1024)\n        return output_path, f\"Complete! {os.path.basename(output_path)} ({file_size:.1f} MB)\"\n    \n    if progress >= 100:\n        return None, \"Completed but file not found\"\n    \n    return None, f\"In Progress: {progress}% - {status_text}\"\n\ndef cleanup_resources():\n    \"\"\"Cleanup video resources\"\"\"\n    global current_video_clip\n    try:\n        if current_video_clip is not None:\n            current_video_clip.close()\n            current_video_clip = None\n    except Exception as e:\n        print(f\"Cleanup error: {e}\")\n\ndef cancel_generation():\n    \"\"\"Cancel video generation\"\"\"\n    global generation_cancelled\n    generation_cancelled = True\n    save_status(\"Cancelled\", 0, error=\"Cancelled by user\")\n    cleanup_resources()\n    return \"Generation cancelled\", None\n    \ndef save_batch_status(total_videos, completed_videos, current_video_info, all_outputs):\n    \"\"\"Save batch generation status\"\"\"\n    try:\n        batch_data = {\n            'total_videos': total_videos,\n            'completed_videos': completed_videos,\n            'current_video': current_video_info,\n            'all_outputs': all_outputs,\n            'timestamp': datetime.now().isoformat()\n        }\n        with open(BATCH_STATUS_FILE, 'w') as f:\n            json.dump(batch_data, f)\n    except Exception as e:\n        print(f\"Error saving batch status: {e}\")\n\ndef load_batch_status():\n    \"\"\"Load batch generation status\"\"\"\n    try:\n        if os.path.exists(BATCH_STATUS_FILE):\n            with open(BATCH_STATUS_FILE, 'r') as f:\n                return json.load(f)\n    except Exception as e:\n        print(f\"Error loading batch status: {e}\")\n    return None","metadata":{"_uuid":"c4efc4b1-4199-4863-adc9-5a37d4660d56","_cell_guid":"cec9778e-1c4e-4dcd-bdb4-f7b83055a8b9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Part 9: TTS Functions**","metadata":{"_uuid":"f1115d9a-5260-4693-aac5-b2e61fffc9bc","_cell_guid":"8c712b9d-38b3-4c4c-b6e7-dcce7604899b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Part 9: TTS Functions - UPDATED with Better Error Handling\n\ndef wave_file(filename, pcm_data, channels=1, rate=24000, sample_width=2):\n    \"\"\"Create a wave file from PCM data\"\"\"\n    try:\n        with wave.open(filename, \"wb\") as wf:\n            wf.setnchannels(channels)\n            wf.setsampwidth(sample_width)\n            wf.setframerate(rate)\n            wf.writeframes(pcm_data)\n        return True\n    except Exception as e:\n        print(f\"Wave file creation error: {e}\")\n        return False\n\ndef generate_tts_audio(text_input, voice_name=\"Puck\", use_rotation=False):\n    \"\"\"Generate TTS audio using Google's Gemini TTS with optional API key rotation\n    ‚úÖ IMPROVED: Better error detection and reporting\"\"\"\n    global generation_cancelled\n    try:\n        if generation_cancelled:\n            return None, \"Cancelled\"\n\n        # Get API key - use rotation if enabled\n        if use_rotation:\n            api_key = get_next_api_key()\n        else:\n            api_key = load_api_key()\n        \n        # Use this specific API key for this call\n        client = genai.Client(api_key=api_key)\n        response = client.models.generate_content(\n            model=\"gemini-2.5-flash-preview-tts\",\n            contents=text_input,\n            config=types.GenerateContentConfig(\n                response_modalities=[\"AUDIO\"],\n                speech_config=types.SpeechConfig(\n                    voice_config=types.VoiceConfig(\n                        prebuilt_voice_config=types.PrebuiltVoiceConfig(\n                            voice_name=voice_name,\n                        )\n                    )\n                ),\n            )\n        )\n\n        if generation_cancelled:\n            return None, \"Cancelled\"\n\n        audio_data = response.candidates[0].content.parts[0].inline_data.data\n        if isinstance(audio_data, str):\n            audio_data = base64.b64decode(audio_data)\n\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        temp_audio_path = f'/tmp/tts_audio_{timestamp}.wav'\n        \n        if wave_file(temp_audio_path, audio_data):\n            return temp_audio_path, \"TTS generated\"\n        else:\n            return None, \"Failed to create audio file\"\n\n    except Exception as e:\n        error_msg = str(e)\n        print(f\"‚ùå TTS Error with current API key: {error_msg}\")\n        \n        # ‚úÖ Detect various quota/rate limit errors\n        error_lower = error_msg.lower()\n        is_quota_error = any(keyword in error_lower for keyword in [\n            \"quota\", \"429\", \"resource_exhausted\", \"rate_limit\", \n            \"limit exceeded\", \"too many requests\", \"resource has been exhausted\"\n        ])\n        \n        is_auth_error = any(keyword in error_lower for keyword in [\n            \"api key\", \"authentication\", \"unauthorized\", \"permission denied\",\n            \"invalid api key\", \"api_key\"\n        ])\n        \n        if is_quota_error:\n            print(f\"‚ö†Ô∏è Quota/Rate limit error detected - will rotate to next key\")\n            return None, f\"TTS Quota Error: {error_msg}\"\n        elif is_auth_error:\n            print(f\"‚ö†Ô∏è Authentication error - API key may be invalid\")\n            return None, f\"TTS Auth Error: {error_msg}\"\n        else:\n            print(f\"‚ö†Ô∏è Other TTS error: {error_msg}\")\n            return None, f\"TTS Error: {error_msg}\"","metadata":{"_uuid":"8d4acf57-2a41-4f07-b08f-91e04296b392","_cell_guid":"b32a1d7d-a701-4ece-bd18-072b82a07e72","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Part 10: Subtitle Functions**","metadata":{"_uuid":"4c9a223f-0695-4fd2-938b-e1fa2650b468","_cell_guid":"6a7c0011-43a0-484c-b432-66c22f958a26","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# ==========================================\n# SUBTITLE FUNCTIONS - FIXED MULTILINGUAL SUPPORT\n# ==========================================\n\nimport urllib.request\n\n# üåç Noto Fonts - Complete language coverage\nFONT_URLS = {\n    'NotoSans-Bold': 'https://github.com/notofonts/notofonts.github.io/raw/main/fonts/NotoSans/hinted/ttf/NotoSans-Bold.ttf',\n    'NotoSans-Regular': 'https://github.com/notofonts/notofonts.github.io/raw/main/fonts/NotoSans/hinted/ttf/NotoSans-Regular.ttf',\n    'NotoSansDevanagari-Bold': 'https://github.com/notofonts/notofonts.github.io/raw/main/fonts/NotoSansDevanagari/hinted/ttf/NotoSansDevanagari-Bold.ttf',\n    'NotoSansDevanagari-Regular': 'https://github.com/notofonts/notofonts.github.io/raw/main/fonts/NotoSansDevanagari/hinted/ttf/NotoSansDevanagari-Regular.ttf',\n    'NotoSansArabic-Bold': 'https://github.com/notofonts/notofonts.github.io/raw/main/fonts/NotoSansArabic/hinted/ttf/NotoSansArabic-Bold.ttf',\n    'NotoSansCJK-Bold': 'https://github.com/notofonts/noto-cjk/raw/main/Sans/OTF/SimplifiedChinese/NotoSansCJKsc-Bold.otf',\n    'NotoSansCJK-Regular': 'https://github.com/notofonts/noto-cjk/raw/main/Sans/OTF/SimplifiedChinese/NotoSansCJKsc-Regular.otf',\n}\n\nFONT_DIR = '/tmp/fonts'\nos.makedirs(FONT_DIR, exist_ok=True)\n\nSUBTITLE_FONTS = {}\nSUBTITLE_FONT_LOADED = False\n\ndef download_subtitle_font(font_name, url):\n    \"\"\"Download font file if not exists\"\"\"\n    font_path = os.path.join(FONT_DIR, font_name + ('.otf' if 'CJK' in font_name else '.ttf'))\n    \n    if os.path.exists(font_path):\n        return font_path\n    \n    try:\n        print(f\"üì• Downloading {font_name}...\")\n        urllib.request.urlretrieve(url, font_path)\n        print(f\"‚úÖ {font_name} ready!\")\n        return font_path\n    except Exception as e:\n        print(f\"‚ö†Ô∏è Failed to download {font_name}: {e}\")\n        return None\n\ndef load_multilingual_subtitle_font():\n    \"\"\"Load all multilingual fonts for subtitles\"\"\"\n    global SUBTITLE_FONTS, SUBTITLE_FONT_LOADED\n    \n    if SUBTITLE_FONT_LOADED and SUBTITLE_FONTS:\n        return True\n    \n    print(\"üî§ Loading subtitle fonts...\")\n    \n    for font_name, url in FONT_URLS.items():\n        path = download_subtitle_font(font_name, url)\n        if path:\n            SUBTITLE_FONTS[font_name] = path\n    \n    if SUBTITLE_FONTS:\n        print(f\"‚úÖ {len(SUBTITLE_FONTS)} subtitle fonts loaded!\\n\")\n        SUBTITLE_FONT_LOADED = True\n        return True\n    else:\n        print(\"‚ö†Ô∏è No fonts loaded, using system defaults\\n\")\n        SUBTITLE_FONT_LOADED = True\n        return False\n\ndef detect_script(text):\n    \"\"\"Detect the primary script in text - IMPROVED\"\"\"\n    if not text:\n        return 'latin'\n    \n    scripts = {\n        'cjk': 0,\n        'arabic': 0,\n        'cyrillic': 0,\n        'devanagari': 0,\n        'latin': 0\n    }\n    \n    for char in text:\n        code = ord(char)\n        # CJK (Chinese, Japanese, Korean)\n        if 0x4E00 <= code <= 0x9FFF or 0x3040 <= code <= 0x30FF or 0xAC00 <= code <= 0xD7AF:\n            scripts['cjk'] += 1\n        # Arabic\n        elif 0x0600 <= code <= 0x06FF or 0x0750 <= code <= 0x077F or 0xFB50 <= code <= 0xFDFF:\n            scripts['arabic'] += 1\n        # Cyrillic (Russian)\n        elif 0x0400 <= code <= 0x04FF:\n            scripts['cyrillic'] += 1\n        # Devanagari (Hindi)\n        elif 0x0900 <= code <= 0x097F:\n            scripts['devanagari'] += 1\n        # Latin\n        elif (0x0020 <= code <= 0x007E) or (0x00A0 <= code <= 0x00FF):\n            scripts['latin'] += 1\n    \n    detected = max(scripts.items(), key=lambda x: x[1])[0]\n    return detected\n\ndef get_subtitle_font_path(text, bold=True):\n    \"\"\"Get the best font path for the given text\"\"\"\n    script = detect_script(text)\n    \n    # Select font based on script\n    if script == 'cjk':\n        font_name = 'NotoSansCJK-Bold' if bold else 'NotoSansCJK-Regular'\n    elif script == 'devanagari':\n        font_name = 'NotoSansDevanagari-Bold' if bold else 'NotoSansDevanagari-Regular'\n    elif script == 'arabic':\n        font_name = 'NotoSansArabic-Bold'\n    else:\n        font_name = 'NotoSans-Bold' if bold else 'NotoSans-Regular'\n    \n    font_path = SUBTITLE_FONTS.get(font_name)\n    \n    if font_path and os.path.exists(font_path):\n        return font_path\n    \n    # Fallback to system fonts\n    system_fonts = [\n        \"/usr/share/fonts/truetype/noto/NotoSans-Bold.ttf\",\n        \"/usr/share/fonts/truetype/noto/NotoSansDevanagari-Bold.ttf\",\n        \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\",\n        \"/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf\"\n    ]\n    \n    for font in system_fonts:\n        if os.path.exists(font):\n            return font\n    \n    return \"Helvetica-Bold\"\n\ndef is_cjk_script(text):\n    \"\"\"Check if text is primarily CJK\"\"\"\n    if not text:\n        return False\n    return detect_script(text) == 'cjk'\n\ndef split_text_into_lines(data):\n    \"\"\"Split transcribed words into subtitle lines\"\"\"\n    if not data:\n        return []\n        \n    MaxChars = 60\n    MaxDuration = 2.5\n    MaxGap = 1.5\n\n    subtitles = []\n    line = []\n    line_duration = 0\n\n    for idx, word_data in enumerate(data):\n        try:\n            word = word_data.get(\"word\", \"\")\n            start = word_data.get(\"start\", 0)\n            end = word_data.get(\"end\", 0)\n\n            line.append(word_data)\n            line_duration += end - start\n            temp = \" \".join(item.get(\"word\", \"\") for item in line)\n\n            new_line_chars = len(temp)\n            duration_exceeded = line_duration > MaxDuration\n            chars_exceeded = new_line_chars > MaxChars\n            sentence_ended = word.rstrip().endswith(('.', '!', '?'))\n\n            if idx > 0:\n                gap = word_data.get('start', 0) - data[idx-1].get('end', 0)\n                maxgap_exceeded = gap > MaxGap\n            else:\n                maxgap_exceeded = False\n\n            if duration_exceeded or chars_exceeded or maxgap_exceeded or sentence_ended:\n                if line:\n                    subtitle_line = {\n                        \"word\": \" \".join(item.get(\"word\", \"\") for item in line),\n                        \"start\": line[0].get(\"start\", 0),\n                        \"end\": line[-1].get(\"end\", 0),\n                        \"textcontents\": line\n                    }\n                    subtitles.append(subtitle_line)\n                    line = []\n                    line_duration = 0\n        except Exception as e:\n            print(f\"Error processing word: {e}\")\n            continue\n\n    if line:\n        try:\n            subtitle_line = {\n                \"word\": \" \".join(item.get(\"word\", \"\") for item in line),\n                \"start\": line[0].get(\"start\", 0),\n                \"end\": line[-1].get(\"end\", 0),\n                \"textcontents\": line\n            }\n            subtitles.append(subtitle_line)\n        except Exception as e:\n            print(f\"Error creating final subtitle: {e}\")\n\n    return subtitles\n\n@lru_cache(maxsize=1000)\ndef get_cached_text_clip(text, font, fontsize, color):\n    \"\"\"Cache text clips for performance - with multilingual font support\"\"\"\n    try:\n        # Get appropriate font for this text\n        if font == \"Helvetica-Bold\" or not font:\n            subtitle_font_path = get_subtitle_font_path(text, bold=True)\n        else:\n            subtitle_font_path = font\n        \n        # If we have a proper font path, use it\n        if subtitle_font_path and subtitle_font_path != \"Helvetica-Bold\" and os.path.exists(subtitle_font_path):\n            return TextClip(text, font=subtitle_font_path, fontsize=fontsize, color=color)\n        else:\n            return TextClip(text, font=font, fontsize=fontsize, color=color)\n    except Exception as e:\n        try:\n            return TextClip(text, fontsize=fontsize, color=color)\n        except Exception as e2:\n            return TextClip(text, color=color)\n\ndef process_voiceover_to_subtitles(voice_over_path):\n    \"\"\"Process audio to generate subtitles using Whisper\"\"\"\n    global generation_cancelled\n    try:\n        if generation_cancelled:\n            return [], \"\"\n\n        print(\"Loading Whisper model...\")\n        model = whisper.load_model(\"tiny\")\n        print(\"Transcribing audio...\")\n        result = model.transcribe(voice_over_path, word_timestamps=True, fp16=False)\n\n        if generation_cancelled:\n            return [], \"\"\n\n        wordlevel_info = []\n        for segment in result.get('segments', []):\n            if generation_cancelled:\n                return [], \"\"\n            if 'words' in segment:\n                for word in segment['words']:\n                    start_time = max(0, word.get('start', 0))\n                    end_time = max(start_time + 0.01, word.get('end', start_time + 0.1))\n\n                    wordlevel_info.append({\n                        'word': word.get('word', '').strip(),\n                        'start': start_time,\n                        'end': end_time\n                    })\n\n        linelevel_subtitles = split_text_into_lines(wordlevel_info)\n        return linelevel_subtitles,result.get('text', '')\n    except Exception as e:\n        print(f\"Subtitle processing error: {e}\")\n        return [], \"\"\n\ndef create_caption(textJSON, framesize, font=\"Helvetica-Bold\", fontsize=14, color='white', aspect_ratio=\"9:16 (Vertical)\"):\n    \"\"\"Create captions with word-by-word highlighting - FIXED FOR CJK\"\"\"\n    try:\n        full_duration = textJSON.get('end', 0) - textJSON.get('start', 0)\n        if full_duration <= 0:\n            return []\n\n        word_clips = []\n        xy_textclips_positions = []\n\n        frame_width = framesize[0]\n        frame_height = framesize[1]\n        \n        subtitle_fontsize = get_subtitle_font_size(aspect_ratio, frame_height)\n        \n        ratio_name = ASPECT_RATIOS[aspect_ratio][\"name\"]\n        if ratio_name == \"9:16\":\n            max_line_width = frame_width * 0.85\n        elif ratio_name == \"16:9\":\n            max_line_width = frame_width * 0.88\n        else:\n            max_line_width = frame_width * 0.85\n\n        # Get full text to check if CJK\n        full_text = textJSON.get('word', '')\n        is_cjk = is_cjk_script(full_text)\n\n        lines = []\n        current_line = []\n        current_line_width = 0\n\n        for wordJSON in textJSON.get('textcontents', []):\n            word_text = wordJSON.get('word', '').strip()\n            \n            # Don't uppercase non-Latin scripts\n            if is_cjk or detect_script(word_text) != 'latin':\n                word_display = word_text\n            else:\n                try:\n                    word_display = word_text.upper()\n                except:\n                    word_display = word_text\n            \n            temp_word = get_cached_text_clip(word_display, font, subtitle_fontsize, color)\n            \n            # Only add space for non-CJK languages\n            if not is_cjk:\n                temp_space = get_cached_text_clip(\" \", font, subtitle_fontsize, color)\n                space_width, _ = temp_space.size\n            else:\n                space_width = 0\n\n            word_width, word_height = temp_word.size\n\n            # Check if we need to break line\n            if current_line_width + word_width + space_width > max_line_width and current_line:\n                lines.append({\n                    'words': current_line.copy(),\n                    'width': current_line_width - (space_width if not is_cjk and current_line else 0),\n                    'height': word_height\n                })\n                current_line = [wordJSON]\n                current_line_width = word_width + space_width\n            else:\n                current_line.append(wordJSON)\n                current_line_width += word_width + space_width\n\n        if current_line:\n            word_display = current_line[0].get('word', '').strip()\n            if is_cjk or detect_script(word_display) != 'latin':\n                pass\n            else:\n                try:\n                    word_display = word_display.upper()\n                except:\n                    pass\n            temp_word = get_cached_text_clip(word_display, font, subtitle_fontsize, color)\n            _, word_height = temp_word.size\n            lines.append({\n                'words': current_line,\n                'width': current_line_width - (space_width if not is_cjk else 0),\n                'height': word_height\n            })\n\n        total_text_height = sum(line['height'] for line in lines) + (len(lines) - 1) * 3\n        subtitle_y_position = get_subtitle_position(aspect_ratio, frame_height)\n        current_y = subtitle_y_position\n\n        if lines:\n            shadow_padding = max(25, int(subtitle_fontsize * 0.6))\n            shadow_height_extra = max(15, int(subtitle_fontsize * 0.35))\n            total_subtitle_width = max(line['width'] for line in lines)\n\n            bg_width = int(total_subtitle_width + shadow_padding * 2)\n            bg_height = int(total_text_height + shadow_height_extra * 2)\n\n            img = Image.new('RGBA', (bg_width, bg_height), (0, 0, 0, 0))\n            draw = ImageDraw.Draw(img)\n\n            draw.rounded_rectangle(\n                [(0, 0), (bg_width-1, bg_height-1)],\n                radius=15,\n                fill=(0, 0, 0, 128)\n            )\n\n            img_array = np.array(img)\n            shadow_bg = ImageClip(img_array, duration=full_duration).set_start(textJSON.get('start', 0))\n\n            shadow_x = (frame_width - total_subtitle_width) / 2 - shadow_padding\n            shadow_y = subtitle_y_position - shadow_height_extra\n            shadow_bg = shadow_bg.set_position((shadow_x, shadow_y))\n            word_clips.append(shadow_bg)\n\n        for line in lines:\n            line_words = line['words']\n            word_dimensions = []\n\n            for wordJSON in line_words:\n                word_text = wordJSON.get('word', '').strip()\n                \n                if is_cjk or detect_script(word_text) != 'latin':\n                    word_display = word_text\n                else:\n                    try:\n                        word_display = word_text.upper()\n                    except:\n                        word_display = word_text\n                \n                temp_word = get_cached_text_clip(word_display, font, subtitle_fontsize, color)\n                word_width, word_height = temp_word.size\n                \n                if not is_cjk:\n                    temp_space = get_cached_text_clip(\" \", font, subtitle_fontsize, color)\n                    space_width, _ = temp_space.size\n                else:\n                    space_width = 0\n\n                word_dimensions.append({\n                    'word_data': wordJSON,\n                    'word_width': word_width,\n                    'word_height': word_height,\n                    'space_width': space_width,\n                    'word_display': word_display\n                })\n\n            line_start_x = (frame_width - line['width']) / 2\n            current_x = line_start_x\n\n            for word_dim in word_dimensions:\n                wordJSON = word_dim['word_data']\n                word_width = word_dim['word_width']\n                word_height = word_dim['word_height']\n                space_width = word_dim['space_width']\n                word_display = word_dim['word_display']\n\n                shadow_text = get_cached_text_clip(word_display, font, subtitle_fontsize, 'black')\n                shadow_text = shadow_text.set_start(textJSON.get('start', 0)).set_duration(full_duration)\n                shadow_text = shadow_text.set_position((current_x + 1, current_y + 1)).set_opacity(0.3)\n                word_clips.append(shadow_text)\n\n                word_clip = get_cached_text_clip(word_display, font, subtitle_fontsize, color)\n                word_clip = word_clip.set_start(textJSON.get('start', 0)).set_duration(full_duration)\n                word_clip = word_clip.set_position((current_x, current_y))\n\n                # Only add space clip for non-CJK\n                if not is_cjk and space_width > 0:\n                    space_clip = get_cached_text_clip(\" \", font, subtitle_fontsize, color)\n                    space_clip = space_clip.set_start(textJSON.get('start', 0)).set_duration(full_duration)\n                    space_clip = space_clip.set_position((current_x + word_width, current_y))\n                    word_clips.append(space_clip)\n\n                word_duration = wordJSON.get('end', 0) - wordJSON.get('start', 0)\n                if word_duration <= 0:\n                    word_duration = 0.1\n\n                xy_textclips_positions.append({\n                    \"x_pos\": current_x,\n                    \"y_pos\": current_y,\n                    \"width\": word_width,\n                    \"height\": word_height,\n                    \"word\": word_display,\n                    \"start\": wordJSON.get('start', 0),\n                    \"end\": wordJSON.get('end', 0),\n                    \"duration\": word_duration\n                })\n\n                word_clips.append(word_clip)\n                current_x += word_width + space_width\n\n            current_y += line['height'] + 3\n\n        for highlight_word in xy_textclips_positions:\n            if highlight_word['duration'] <= 0:\n                continue\n\n            bg_width = int(highlight_word['width'] + max(16, int(subtitle_fontsize * 0.38)))\n            bg_height = int(highlight_word['height'] + max(8, int(subtitle_fontsize * 0.19)))\n\n            img = Image.new('RGBA', (bg_width, bg_height), (0, 0, 0, 0))\n            draw = ImageDraw.Draw(img)\n\n            draw.rounded_rectangle(\n                [(0, 0), (bg_width-1, bg_height-1)],\n                radius=8,\n                fill=(147, 0, 211, 180)\n            )\n\n            img_array = np.array(img)\n            bg_clip = ImageClip(img_array, duration=highlight_word['duration'])\n            bg_clip = bg_clip.set_start(highlight_word['start'])\n\n            bg_x = highlight_word['x_pos'] - max(8, int(subtitle_fontsize * 0.19))\n            bg_y = highlight_word['y_pos'] - max(4, int(subtitle_fontsize * 0.095))\n            bg_clip = bg_clip.set_position((bg_x, bg_y))\n\n            shadow_highlight = get_cached_text_clip(highlight_word['word'], font, subtitle_fontsize, 'black')\n            shadow_highlight = shadow_highlight.set_start(highlight_word['start']).set_duration(highlight_word['duration'])\n            shadow_highlight = shadow_highlight.set_position((highlight_word['x_pos'] + 1, highlight_word['y_pos'] + 1)).set_opacity(0.4)\n\n            word_clip_highlight = get_cached_text_clip(highlight_word['word'], font, subtitle_fontsize, 'white')\n            word_clip_highlight = word_clip_highlight.set_start(highlight_word['start']).set_duration(highlight_word['duration'])\n            word_clip_highlight = word_clip_highlight.set_position((highlight_word['x_pos'], highlight_word['y_pos']))\n\n            word_clips.append(bg_clip)\n            word_clips.append(shadow_highlight)\n            word_clips.append(word_clip_highlight)\n\n        return word_clips\n        \n    except Exception as e:\n        print(f\"Error creating caption: {e}\")\n        import traceback\n        traceback.print_exc()\n        return []\n\n# Load fonts on module initialization\nload_multilingual_subtitle_font()","metadata":{"_uuid":"c074c12f-7fcf-4154-999c-30139fcb33d8","_cell_guid":"7fc06e36-6af8-42fb-a8fb-ad2ea2f50e22","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Part 11: Video Processing Functions**","metadata":{"_uuid":"6216dc5f-9574-4136-a3f4-08e48301646a","_cell_guid":"1f5e6e32-2c06-4f4e-bb68-bc00a4f03a0c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# =========================================\n# VIDEO PROCESSING FUNCTIONS - FIXED MULTILINGUAL SUPPORT\n# =========================================\n\n\ndef create_title_overlay(title_text, framesize, duration=4, aspect_ratio=\"9:16 (Vertical)\"):\n    \"\"\"Create 3D-style title - UPDATED with new vertical position\"\"\"\n    if not title_text or title_text.strip() == \"\":\n        return []\n\n    try:\n        frame_width, frame_height = framesize\n\n        # Detect script and select appropriate font\n        script = detect_script(title_text)\n\n        if script == 'cjk':\n            TITLE_FONT_URL = \"https://github.com/notofonts/noto-cjk/raw/main/Sans/OTF/SimplifiedChinese/NotoSansCJKsc-Bold.otf\"\n            TITLE_FONT_PATH = \"/tmp/NotoSansCJK-Bold-Title.otf\"\n        elif script == 'devanagari':\n            TITLE_FONT_URL = \"https://github.com/notofonts/notofonts.github.io/raw/main/fonts/NotoSansDevanagari/hinted/ttf/NotoSansDevanagari-Bold.ttf\"\n            TITLE_FONT_PATH = \"/tmp/NotoSansDevanagari-Bold-Title.ttf\"\n        elif script == 'arabic':\n            TITLE_FONT_URL = \"https://github.com/notofonts/notofonts.github.io/raw/main/fonts/NotoSansArabic/hinted/ttf/NotoSansArabic-Bold.ttf\"\n            TITLE_FONT_PATH = \"/tmp/NotoSansArabic-Bold-Title.ttf\"\n        else:\n            TITLE_FONT_URL = \"https://github.com/notofonts/notofonts.github.io/raw/main/fonts/NotoSans/hinted/ttf/NotoSans-Bold.ttf\"\n            TITLE_FONT_PATH = \"/tmp/NotoSans-Bold-Title.ttf\"\n\n        # Download font if needed\n        title_font_path = None\n        if not os.path.exists(TITLE_FONT_PATH):\n            try:\n                print(f\"üì• Downloading {script} font for title...\")\n                urllib.request.urlretrieve(TITLE_FONT_URL, TITLE_FONT_PATH)\n                print(f\"‚úÖ Title font ready for {script}\")\n            except Exception as e:\n                print(f\"‚ö†Ô∏è Font download failed: {e}\")\n\n        if os.path.exists(TITLE_FONT_PATH):\n            title_font_path = TITLE_FONT_PATH\n\n        base_margin = get_title_position(aspect_ratio, frame_height)\n\n        POSITION_ADJUSTMENT = int(frame_height * 0.035)\n        TOP_MARGIN = int(base_margin * 0.65) + POSITION_ADJUSTMENT\n\n        # Dynamically set font size based on aspect ratio\n        ratio_name = ASPECT_RATIOS[aspect_ratio][\"name\"]\n        if ratio_name == \"9:16\":\n            FONT_SIZE = int(frame_height * 0.0413712)\n        elif ratio_name in [\"4:5\", \"1:1\"]:\n            # üéØ Increased 4:5 size by 10% and matched 1:1 to it\n            FONT_SIZE = int(frame_height * 0.0572)\n        else:\n            # Original size for other ratios (i.e., 16:9)\n            FONT_SIZE = int(frame_height * 0.052)\n\n        BLACK = (0, 0, 0)\n        WHITE = (255, 255, 255)\n\n        EXTRUDE_DEPTH = max(3, int(frame_height * 0.007))\n        GLOW_RADIUS = max(6, int(frame_height * 0.012))\n        STROKE_WIDTH = max(2, int(frame_height * 0.004))\n\n        MAX_LINES = 4\n        LINE_SPACING = max(3, int(frame_height * 0.006))\n\n        def load_font(size):\n            try:\n                if title_font_path and os.path.exists(title_font_path):\n                    return ImageFont.truetype(title_font_path, size)\n            except Exception as e:\n                print(f\"‚ö†Ô∏è Font load failed: {e}\")\n\n            system_fonts = [\n                \"/usr/share/fonts/truetype/noto/NotoSans-Bold.ttf\",\n                \"/usr/share/fonts/truetype/noto/NotoSansDevanagari-Bold.ttf\",\n                \"/usr/share/fonts/truetype/noto/NotoSansCJK-Bold.ttc\",\n                \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\",\n                \"/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf\",\n            ]\n\n            for font_path in system_fonts:\n                try:\n                    if os.path.exists(font_path): return ImageFont.truetype(font_path, size)\n                except: continue\n\n            print(\"‚ö†Ô∏è Using default font\")\n            return ImageFont.load_default()\n\n        font_obj = load_font(FONT_SIZE)\n        temp_img = Image.new(\"RGBA\", (frame_width, frame_height), (0,0,0,0))\n        temp_draw = ImageDraw.Draw(temp_img)\n\n        def measure_text(text, font):\n            try:\n                bbox = temp_draw.textbbox((0,0), text, font=font, stroke_width=STROKE_WIDTH)\n                return bbox[2]-bbox[0], bbox[3]-bbox[1]\n            except:\n                return 100, 50\n\n        def wrap_text_fixed_size(text, font, max_width):\n            is_cjk = is_cjk_script(text)\n            if not is_cjk and detect_script(text) == 'latin':\n                try: text = text.upper()\n                except: pass\n\n            if is_cjk:\n                lines, current = [], \"\"\n                for char in text:\n                    w, _ = measure_text(current + char, font)\n                    if w <= max_width: current += char\n                    else:\n                        if current: lines.append(current)\n                        current = char\n                if current: lines.append(current)\n                return lines\n            else:\n                words, lines, current = text.split(), [], []\n                for word in words:\n                    w, _ = measure_text(\" \".join(current + [word]), font)\n                    if w <= max_width: current.append(word)\n                    else:\n                        if current: lines.append(\" \".join(current))\n                        current = [word] if word else []\n                if current: lines.append(\" \".join(current))\n                return lines\n\n        max_width = frame_width * 0.88\n        lines = wrap_text_fixed_size(title_text, font_obj, max_width)\n\n        if len(lines) > MAX_LINES: lines = lines[:MAX_LINES]\n\n        line_heights = [measure_text(line, font_obj)[1] for line in lines]\n        y_start = TOP_MARGIN\n        x_center = frame_width // 2\n        base = Image.new(\"RGBA\", (frame_width, frame_height), (0, 0, 0, 0))\n\n        background_layer = Image.new(\"RGBA\", (frame_width, frame_height), (0, 0, 0, 0))\n        bg_draw = ImageDraw.Draw(background_layer)\n        y_cursor = y_start\n\n        padding = int(FONT_SIZE * 0.25)\n        radius = int(FONT_SIZE * 0.3)\n\n        for i, line in enumerate(lines):\n            line_width, _ = measure_text(line, font_obj)\n            x = x_center - line_width // 2\n            y = y_cursor\n\n            bbox = bg_draw.textbbox((x, y), line, font=font_obj, stroke_width=STROKE_WIDTH)\n\n            bg_draw.rounded_rectangle(\n                [(bbox[0] - padding, bbox[1] - padding), (bbox[2] + padding, bbox[3] + padding)],\n                radius=radius,\n                fill=(0, 0, 0, 112)\n            )\n\n            y_cursor += line_heights[i] + LINE_SPACING\n\n        base = Image.alpha_composite(base, background_layer)\n\n        def draw_text_lines(target_draw, lines, x_center, y_start, font, **kwargs):\n            y = y_start\n            for i, line in enumerate(lines):\n                w, _ = measure_text(line, font)\n                x = x_center - w // 2\n                target_draw.text((x, y), line, font=font, **kwargs)\n                y += line_heights[i] + LINE_SPACING\n\n        extrude_layer = Image.new(\"RGBA\", (frame_width, frame_height), (0, 0, 0, 0))\n        ext_draw = ImageDraw.Draw(extrude_layer)\n        for i in range(EXTRUDE_DEPTH, 0, -1):\n            alpha = int(255 * (i / EXTRUDE_DEPTH) * 0.3)\n            draw_text_lines(ext_draw, lines, x_center + i, y_start + i // 2, font_obj, fill=(0, 0, 0, alpha))\n        extrude_layer = extrude_layer.filter(ImageFilter.GaussianBlur(1))\n        base = Image.alpha_composite(base, extrude_layer)\n\n        glow_layer = Image.new(\"RGBA\", (frame_width, frame_height), (0, 0, 0, 0))\n        glow_draw = ImageDraw.Draw(glow_layer)\n        draw_text_lines(glow_draw, lines, x_center, y_start, font_obj, fill=(0, 0, 0, 100))\n        glow_layer = glow_layer.filter(ImageFilter.GaussianBlur(GLOW_RADIUS))\n        base = Image.alpha_composite(base, glow_layer)\n\n        shadow_layer = Image.new(\"RGBA\", (frame_width, frame_height), (0, 0, 0, 0))\n        shadow_draw = ImageDraw.Draw(shadow_layer)\n        draw_text_lines(shadow_draw, lines, x_center + 2, y_start + 2, font_obj, fill=(20, 20, 20, 180))\n        base = Image.alpha_composite(base, shadow_layer)\n\n        final_draw = ImageDraw.Draw(base)\n        draw_text_lines(final_draw, lines, x_center, y_start, font_obj, fill=WHITE, stroke_width=STROKE_WIDTH, stroke_fill=BLACK)\n\n        img_array = np.array(base)\n        title_clip = ImageClip(img_array, duration=duration)\n        return [title_clip]\n    except Exception as e:\n        print(f\"Error creating title: {e}\")\n        import traceback\n        traceback.print_exc()\n        return []\n\n\ndef get_random_subclip_and_slow(clip):\n    \"\"\"Get random subclip and apply slow motion - REMOVE AUDIO\"\"\"\n    try:\n        clip_no_audio = clip.without_audio()\n\n        subclip_durations = [2, 3, 4]\n        subclip_duration = random.choice(subclip_durations)\n\n        if clip_no_audio.duration < subclip_duration:\n            return clip_no_audio.speedx(0.5)\n\n        max_start_time = max(0, clip_no_audio.duration - subclip_duration)\n        start_time = random.uniform(0, max_start_time)\n        end_time = min(start_time + subclip_duration, clip_no_audio.duration)\n\n        subclip = clip_no_audio.subclip(start_time, end_time)\n        return subclip.speedx(0.5)\n    except Exception as e:\n        print(f\"Error processing subclip: {e}\")\n        return clip.without_audio() if hasattr(clip, 'without_audio') else clip\n\n\ndef ensure_even_dimensions(clip):\n    \"\"\"Ensure video dimensions are even numbers for encoding\"\"\"\n    try:\n        width, height = clip.size\n        if width % 2 != 0: width -= 1\n        if height % 2 != 0: height -= 1\n        if (width, height) != clip.size:\n            return clip.resize((width, height))\n        return clip\n    except Exception as e:\n        print(f\"Error ensuring even dimensions: {e}\")\n        return clip\n\n# =========================================\n# UNIVERSAL SENTENCE DETECTION FOR ALL LANGUAGES\n# =========================================\n\n\ndef get_sentence_endings():\n    \"\"\"Get all sentence ending punctuation marks from all languages\"\"\"\n    return [\n        '.', '!', '?', '„ÄÇ', 'ÔºÅ', 'Ôºü', '‡•§', '‡••', '€î', 'ÿü', 'ÿõ', '÷â', '’ú', '’û', '·ç¢', '·çß', '·ç®',\n        '·Åã', '·Åä', '‡∏Ø', '‡ºç', '‡ºé', '‡ºè', '‡ºê', '‡ºë', '‡ºî', '·†É', '·†â', '·ôÆ', '·•Ñ', '·•Ö', '·•Ü',\n        '·ßû', '·ßü', '·ß©', '·™©', '·™™', '·™´', '·≠û', '·≠ü', '·≠ö', '·≠õ', '·≠ú', '·≠ù', '·≠û', '·≠ü',\n        'Ôπí', 'Ôπî', 'Ôπï', 'ÔºÅ', 'Ôºü', 'Ôºé', 'ÔºÅ', 'Ôºü',\n    ]\n\n\ndef is_sentence_ending(char):\n    \"\"\"Check if character is a sentence ending in any language\"\"\"\n    return char in get_sentence_endings()\n\n\ndef extract_title_from_script(text_input):\n    \"\"\"\n    Extract the title from the script.\n    The title is everything up to the first punctuation mark OR the first line break.\n    \"\"\"\n    if not text_input or not text_input.strip():\n        return \"\"\n\n    text = text_input.strip()\n\n    # Find the index of the first sentence-ending punctuation\n    punct_end_idx = -1\n    for i, char in enumerate(text):\n        if is_sentence_ending(char):\n            punct_end_idx = i\n            break\n\n    # Find the index of the first newline character\n    newline_end_idx = text.find('\\n')\n\n    # Determine the actual end of the title by finding the first separator\n    title_end_idx = -1\n    indices = [i for i in [punct_end_idx, newline_end_idx] if i != -1]\n    if not indices:\n        # No separator found, the whole text is the title\n        title_end_idx = len(text)\n    else:\n        title_end_idx = min(indices)\n\n    # Extract the title. If punctuation was the separator, include it.\n    if title_end_idx == punct_end_idx:\n        title = text[:title_end_idx + 1].strip()\n    else:\n        # If newline or end-of-string was the separator, don't include it.\n        title = text[:title_end_idx].strip()\n\n    # Apply existing truncation logic for long titles\n    script = detect_script(title)\n    max_length = 150 if script in ['cjk', 'devanagari', 'arabic'] else 100\n\n    if len(title) > max_length:\n        if script != 'cjk':\n            truncated = title[:max_length - 3]\n            last_space = truncated.rfind(' ')\n            title = truncated[:last_space] + \"...\" if last_space > max_length * 0.7 else truncated + \"...\"\n        else:\n            title = title[:max_length - 1] + \"‚Ä¶\"\n\n    return title\n\n\ndef remove_title_from_script(text_input):\n    \"\"\"\n    Remove the title (as defined by extract_title_from_script) from the script.\n    \"\"\"\n    if not text_input or not text_input.strip():\n        return text_input\n\n    text = text_input.strip()\n\n    # Find the separator index using the same logic as the extraction function\n    punct_end_idx = -1\n    for i, char in enumerate(text):\n        if is_sentence_ending(char):\n            punct_end_idx = i\n            break\n    newline_end_idx = text.find('\\n')\n\n    separator_idx = -1\n    indices = [i for i in [punct_end_idx, newline_end_idx] if i != -1]\n\n    if indices:\n        separator_idx = min(indices)\n        # The content starts right after the separator\n        remaining = text[separator_idx + 1:].strip()\n        return remaining\n    else:\n        # No separator found, implies the whole text was the title, so no content remains\n        return \"\"\n\n\ndef split_script_by_separator(text_input, separator=\"---\", remove_first_line_as_title=False):\n    \"\"\"Split script into multiple parts based on separator\"\"\"\n    if not text_input or not text_input.strip(): return []\n\n    script_to_process = remove_title_from_script(text_input) if remove_first_line_as_title else text_input\n    parts = script_to_process.split(separator)\n\n    script_parts = []\n    for i, part in enumerate(parts):\n        cleaned = part.strip()\n        if cleaned:\n            word_count = len(cleaned.replace(' ', '')) if is_cjk_script(cleaned) else len(cleaned.split())\n            script_parts.append({'index': i + 1, 'text': cleaned, 'word_count': word_count})\n\n    return script_parts\n\n\ndef estimate_script_duration(text):\n    \"\"\"Estimate duration based on word/character count\"\"\"\n    if is_cjk_script(text):\n        char_count = len(text.replace(' ', ''))\n        estimated_seconds = (char_count / 250) * 60\n    else:\n        word_count = len(text.split())\n        estimated_seconds = (word_count / 150) * 60\n\n    return max(1, int(estimated_seconds / 60))","metadata":{"_uuid":"a700efc0-9775-4772-af4b-b6495e4d0337","_cell_guid":"dfc3fd25-eba5-427c-ae5e-aeb3cf836bdc","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Part 12: Main Video Generation Function**","metadata":{"_uuid":"ef76d599-7767-402a-a3f2-ae0826069948","_cell_guid":"9e4beb6a-b4ad-4bdc-945b-f2e528ace5e8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Part 12: Main Video Generation Function - UPDATED with Improved API Rotation and NO background video transparency\n\ndef merge_videos_with_subtitles(text_input, voice_selection, audio_input, title_text, \n                                duration_minutes, video_quality, aspect_ratio,\n                                video_folder_path, music_folder_path, \n                                auto_title_enabled,\n                                progress=gr.Progress(track_tqdm=True)):\n    \"\"\"Main video generation function with script splitting support\"\"\"\n    global generation_cancelled, current_video_clip\n\n    generation_cancelled = False\n    current_video_clip = None\n\n    try:\n        save_ui_state(text_input, voice_selection, title_text, duration_minutes, video_quality, auto_title_enabled)\n        \n        # Check if script contains separators (batch mode)\n        if text_input and text_input.strip() and \"---\" in text_input:\n            # BATCH MODE - Extract titles from each part\n            script_parts_raw = text_input.split(\"---\")\n            script_parts = []\n            \n            for i, part in enumerate(script_parts_raw):\n                cleaned = part.strip()\n                if cleaned:\n                    # Extract title from THIS part (first line)\n                    part_title = \"\"\n                    part_content_with_title = cleaned\n                    \n                    if auto_title_enabled:\n                        part_title = extract_title_from_script(cleaned)\n                    \n                    # Override with manual title if provided\n                    if title_text and title_text.strip():\n                        part_title = title_text.strip()\n                    \n                    script_parts.append({\n                        'index': i + 1,\n                        'text': part_content_with_title,\n                        'title': part_title,\n                    })\n            \n            print(f\"üìã Detected {len(script_parts)} script parts to generate\")\n            \n            if len(script_parts) > 1:\n                return generate_batch_videos(\n                    script_parts, voice_selection, video_quality, aspect_ratio, \n                    video_folder_path, music_folder_path, auto_title_enabled, progress\n                )\n        \n        # SINGLE VIDEO MODE\n        actual_title = \"\"\n        script_for_tts = text_input\n        \n        if auto_title_enabled and text_input and text_input.strip():\n            extracted_title = extract_title_from_script(text_input)\n            actual_title = title_text.strip() if title_text and title_text.strip() else extracted_title\n            script_for_tts = text_input\n            print(f\"üìå Using Title: '{actual_title}'\")\n            print(f\"üî¢ Title will be spoken in voice-over\")\n        else:\n            actual_title = title_text.strip() if title_text and title_text.strip() else \"\"\n            script_for_tts = text_input\n        \n        return generate_single_video(\n            script_for_tts, voice_selection, audio_input, actual_title,\n            duration_minutes, video_quality, aspect_ratio,\n            video_folder_path, music_folder_path, auto_title_enabled, progress\n        )\n\n    except Exception as e:\n        save_status(\"Error\", 0, error=str(e))\n        cleanup_resources()\n        import traceback\n        traceback.print_exc()\n        return None, f\"Error: {str(e)}\", gr.Dropdown(choices=get_history_choices())\n\n\ndef generate_batch_videos(script_parts, voice_selection, video_quality, aspect_ratio, \n                          video_folder_path, music_folder_path, auto_title_enabled, \n                          progress=gr.Progress(track_tqdm=True)):\n    \"\"\"Generate multiple videos from split script - Each with its own title\n    ‚úÖ IMPROVED: Continues generating remaining videos even if one fails\"\"\"\n    global generation_cancelled, current_api_key_index\n    \n    import random\n    current_api_key_index = random.randint(0, len(API_KEYS) - 1)\n    print(f\"üé≤ Starting from random API key position: {current_api_key_index + 1}/{len(API_KEYS)}\")\n    \n    total_parts = len(script_parts)\n    all_output_paths = []\n    all_summaries = []\n    failed_parts = []\n    \n    try:\n        print(f\"\\n{'='*60}\")\n        print(f\"üé¨ BATCH GENERATION START\")\n        print(f\"{'='*60}\")\n        print(f\"Total videos to generate: {total_parts}\")\n        print(f\"Available API keys: {len(API_KEYS)}\")\n        print(f\"Starting position: Key #{current_api_key_index + 1}\")\n        print(f\"{'='*60}\\n\")\n        \n        for part_idx, script_part in enumerate(script_parts):\n            if generation_cancelled:\n                summary = f\"‚ö†Ô∏è Batch cancelled after {len(all_output_paths)}/{total_parts} videos\\n\"\n                summary += f\"‚úÖ Completed: {len(all_output_paths)} | ‚ùå Failed: {len(failed_parts)}\"\n                return None, summary, gr.Dropdown(choices=get_history_choices())\n            \n            part_num = script_part['index']\n            part_text = script_part['text']\n            part_title = script_part['title']\n            \n            save_batch_status(\n                total_videos=total_parts,\n                completed_videos=len(all_output_paths),\n                current_video_info=f\"Part {part_num}/{total_parts}\",\n                all_outputs=all_output_paths\n            )\n            \n            print(f\"\\n{'='*60}\")\n            print(f\"üé¨ Generating Video {part_num}/{total_parts}\")\n            print(f\"üîë {get_api_rotation_status()}\")\n            if part_title:\n                print(f\"üìå Title: '{part_title}'\")\n                print(f\"üî¢ Title included in voice-over\")\n            else:\n                print(f\"üìå No title\")\n            print(f\"{'='*60}\\n\")\n            \n            estimated_duration = estimate_script_duration(part_text)\n            \n            def part_progress(p, desc=\"\"):\n                overall_progress = (len(all_output_paths) + p) / total_parts\n                progress(overall_progress, desc=f\"Video {part_num}/{total_parts}: {desc}\")\n            \n            try:\n                video_path, summary, _ = generate_single_video_with_retry(\n                    text_input=part_text,\n                    voice_selection=voice_selection,\n                    audio_input=None,\n                    title_text=part_title,\n                    duration_minutes=estimated_duration,\n                    video_quality=video_quality,\n                    aspect_ratio=aspect_ratio,\n                    video_folder_path=video_folder_path,\n                    music_folder_path=music_folder_path,\n                    auto_title_enabled=auto_title_enabled,\n                    progress=part_progress,\n                    part_number=part_num,\n                    total_parts=total_parts\n                )\n                \n                if video_path and os.path.exists(video_path):\n                    all_output_paths.append(video_path)\n                    title_info = f\"Title: '{part_title}'\" if part_title else \"No title\"\n                    all_summaries.append(f\"‚úÖ Video {part_num}: {os.path.basename(video_path)} | {title_info}\")\n                    print(f\"‚úÖ Video {part_num}/{total_parts} completed successfully\")\n                else:\n                    failed_parts.append(part_num)\n                    error_msg = summary[:100] if summary else \"Unknown error\"\n                    all_summaries.append(f\"‚ùå Video {part_num}: FAILED - {error_msg}\")\n                    print(f\"‚ùå Video {part_num}/{total_parts} failed - continuing with next video...\")\n                    print(f\"   Error: {error_msg}\")\n                    \n            except Exception as e:\n                failed_parts.append(part_num)\n                error_msg = str(e)[:100]\n                all_summaries.append(f\"‚ùå Video {part_num}: EXCEPTION - {error_msg}\")\n                print(f\"‚ùå Video {part_num}/{total_parts} exception - continuing with next video...\")\n                print(f\"   Exception: {error_msg}\")\n                continue\n        \n        success_count = len(all_output_paths)\n        fail_count = len(failed_parts)\n        \n        if all_output_paths:\n            final_summary = f\"\"\"‚úÖ Batch Complete!\n\nüìä Results:\n‚Ä¢ Total videos: {total_parts}\n‚Ä¢ ‚úÖ Successful: {success_count}\n‚Ä¢ ‚ùå Failed: {fail_count}\n\nGenerated Videos:\n\"\"\"\n            for summary_line in all_summaries:\n                final_summary += f\"{summary_line}\\n\"\n            \n            if failed_parts:\n                final_summary += f\"\\n‚ö†Ô∏è Failed parts: {', '.join(map(str, failed_parts))}\"\n                final_summary += f\"\\nüí° Tip: Check if those parts have issues or try regenerating them individually\"\n            \n            final_summary += f\"\\n\\nüìÅ All videos saved to: {OUTPUT_PATH}\"\n            \n            last_video = all_output_paths[-1] if all_output_paths else None\n            return last_video, final_summary, gr.Dropdown(choices=get_history_choices())\n        else:\n            final_summary = f\"\"\"‚ùå Batch Failed - No videos generated\n\nüìä Status:\n‚Ä¢ Total attempted: {total_parts}\n‚Ä¢ All parts failed after trying all {len(API_KEYS)} API keys\n\nFailed parts: {', '.join(map(str, failed_parts))}\n\nüí° Troubleshooting:\n1. Check if all API keys are valid\n2. Verify script content is correct\n3. Check video folder exists\n4. Try generating a single video first\n\"\"\"\n            return None, final_summary, gr.Dropdown(choices=get_history_choices())\n    \n    except Exception as e:\n        import traceback\n        traceback.print_exc()\n        summary = f\"\"\"‚ùå Batch error\n        \n‚úÖ Completed: {len(all_output_paths)}/{total_parts}\n‚ùå Failed: {len(failed_parts)}\n\nError: {str(e)[:200]}\n\nCompleted videos are saved in {OUTPUT_PATH}\n\"\"\"\n        return None, summary, gr.Dropdown(choices=get_history_choices())\n\n\ndef generate_single_video_with_retry(text_input, voice_selection, audio_input, title_text,\n                                      duration_minutes, video_quality, aspect_ratio,\n                                      video_folder_path, music_folder_path,\n                                      auto_title_enabled, progress,\n                                      part_number=None, total_parts=None):\n    \"\"\"\n    Wrapper function that retries with different API keys if TTS fails\n    \"\"\"\n    max_retries = len(API_KEYS)\n    last_error = None\n    \n    for attempt in range(max_retries):\n        if generation_cancelled:\n            return None, \"Cancelled\", gr.Dropdown(choices=get_history_choices())\n        \n        current_key_status = get_api_rotation_status()\n        print(f\"\\nüîÑ Attempt {attempt + 1}/{max_retries} | {current_key_status}\")\n        \n        try:\n            result = generate_single_video(\n                text_input=text_input,\n                voice_selection=voice_selection,\n                audio_input=audio_input,\n                title_text=title_text,\n                duration_minutes=duration_minutes,\n                video_quality=video_quality,\n                aspect_ratio=aspect_ratio,\n                video_folder_path=video_folder_path,\n                music_folder_path=music_folder_path,\n                auto_title_enabled=auto_title_enabled,\n                progress=progress,\n                part_number=part_number,\n                total_parts=total_parts,\n                use_api_rotation=True\n            )\n            \n            video_path, summary, history = result\n            \n            if video_path and os.path.exists(video_path):\n                print(f\"‚úÖ Success on attempt {attempt + 1} with {current_key_status}\")\n                return result\n            \n            error_lower = summary.lower()\n            is_tts_error = any(keyword in error_lower for keyword in [\n                \"tts\", \"quota\", \"429\", \"resource_exhausted\", \n                \"rate_limit\", \"api key\", \"authentication\", \"permission\"\n            ])\n            \n            if is_tts_error:\n                last_error = summary\n                print(f\"‚ö†Ô∏è TTS/API error on attempt {attempt + 1}: {summary[:100]}\")\n                print(f\"üîÑ Rotating to next API key...\")\n                continue\n            else:\n                print(f\"‚ùå Non-TTS error (not retrying): {summary}\")\n                return result\n                \n        except Exception as e:\n            last_error = str(e)\n            error_str = str(e).lower()\n            is_api_error = any(keyword in error_str for keyword in [\n                \"quota\", \"429\", \"rate_limit\", \"api\", \"authentication\"\n            ])\n            \n            if is_api_error and attempt < max_retries - 1:\n                print(f\"‚ö†Ô∏è Exception with API key (attempt {attempt + 1}): {str(e)[:100]}\")\n                print(f\"üîÑ Trying next API key...\")\n                continue\n            else:\n                print(f\"‚ùå Fatal exception: {str(e)}\")\n                return None, f\"Error: {str(e)}\", gr.Dropdown(choices=get_history_choices())\n    \n    print(f\"‚ùå All {max_retries} API keys exhausted\")\n    print(f\"Last error: {last_error}\")\n    return None, f\"Failed after trying all {max_retries} API keys. Last error: {last_error}\", gr.Dropdown(choices=get_history_choices())\n\n\ndef generate_single_video(text_input, voice_selection, audio_input, title_text,\n                          duration_minutes, video_quality, aspect_ratio,\n                          video_folder_path, music_folder_path,\n                          auto_title_enabled,\n                          progress=gr.Progress(track_tqdm=True),\n                          part_number=None, total_parts=None,\n                          use_api_rotation=False):\n    \"\"\"Generate a single video - with optional API key rotation\"\"\"\n    global generation_cancelled, current_video_clip\n\n    try:\n        save_status(\"Initializing\", 0)\n        progress(0, desc=\"Starting...\")\n        print(\"Starting video generation...\")\n        \n        if use_api_rotation:\n            print(f\"üîë API Rotation: ENABLED | {get_api_rotation_status()}\")\n        \n        if title_text:\n            print(f\"üéØ Title for overlay: '{title_text}'\")\n        if auto_title_enabled:\n            print(f\"üî¢ Title is included in voice-over (first line will be spoken)\")\n\n        if generation_cancelled:\n            return None, \"Cancelled\", gr.Dropdown(choices=get_history_choices())\n\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        \n        source_path = None\n        if video_folder_path and video_folder_path != \"\" and os.path.isdir(video_folder_path):\n            source_path = video_folder_path\n            print(f\"Using video folder: {source_path}\")\n        else:\n            video_paths = [\n                '/kaggle/input/video-clips', '/kaggle/input/video_clips', \n                '/kaggle/input/videos', '/kaggle/working/video_clips'\n            ]\n            for path in video_paths:\n                if os.path.isdir(path):\n                    source_path = path\n                    print(f\"Found video source: {path}\")\n                    break\n        \n        if not source_path:\n            save_status(\"Error: Video clips not found\", 0, error=\"No video folder\")\n            return None, \"No video folder found. Please select a folder.\", gr.Dropdown(choices=get_history_choices())\n\n        save_status(\"Finding background music\", 2)\n        background_music_path = None\n        \n        if music_folder_path and music_folder_path != \"\" and os.path.isdir(music_folder_path):\n            background_music_path = get_random_music_file(music_folder_path)\n            if background_music_path:\n                print(f\"Selected: {os.path.basename(background_music_path)}\")\n        else:\n            default_music = get_default_music_folder()\n            if default_music:\n                background_music_path = get_random_music_file(default_music)\n                if background_music_path:\n                    print(f\"Auto-selected: {os.path.basename(background_music_path)}\")\n        \n        if not background_music_path:\n            print(\"No background music\")\n\n        os.makedirs(OUTPUT_PATH, exist_ok=True)\n\n        video_extensions = ('.mp4', '.avi', '.mkv', '.mov', '.MP4', '.AVI', '.MKV', '.MOV')\n        all_files = [f for f in os.listdir(source_path) if f.endswith(video_extensions)]\n\n        if not all_files:\n            save_status(\"Error: No video files\", 0, error=\"No videos found\")\n            return None, f\"No videos in {os.path.basename(source_path)}\", gr.Dropdown(choices=get_history_choices())\n\n        # üéØ HYPER-RANDOMIZATION LOGIC\n        print(f\"Found {len(all_files)} videos.\")\n        seed_value = int(time.time() * 1000) + os.getpid() + random.randint(0, 1_000_000)\n        random.seed(seed_value)\n        print(f\"Hyper-randomizing clip selection with seed: {seed_value}\")\n        \n        shuffle_count = random.randint(5, 15)\n        for i in range(shuffle_count):\n            random.shuffle(all_files)\n            print(f\"  Shuffle pass {i+1}/{shuffle_count}...\")\n        print(\"‚úÖ Video clip list is now hyper-randomized.\")\n\n        target_duration_seconds = duration_minutes * 60\n        voice_over_audio = None\n        linelevel_subtitles = []\n        voice_over_path = None\n\n        if text_input and text_input.strip():\n            save_status(\"Generating TTS\", 10)\n            progress(0.1, desc=\"TTS...\")\n            print(\"Generating TTS...\")\n            print(f\"üìÑ Script includes: '{text_input[:100]}...'\")\n            voice_name = AVAILABLE_VOICES.get(voice_selection, {}).get(\"name\", \"Puck\")\n            \n            tts_path, tts_message = generate_tts_audio(text_input, voice_name, use_rotation=use_api_rotation)\n\n            if generation_cancelled:\n                return None, \"Cancelled\", gr.Dropdown(choices=get_history_choices())\n\n            if tts_path:\n                voice_over_folder_path = '/kaggle/working/voice_over'\n                os.makedirs(voice_over_folder_path, exist_ok=True)\n                voice_filename = f\"tts_{timestamp}.wav\"\n                if part_number:\n                    voice_filename = f\"tts_part{part_number}_{timestamp}.wav\"\n                saved_voice_path = os.path.join(voice_over_folder_path, voice_filename)\n                shutil.copy2(tts_path, saved_voice_path)\n                voice_over_path = saved_voice_path\n                print(\"‚úÖ TTS generation successful (includes title in voice)\")\n            else:\n                save_status(\"TTS failed\", 10, error=tts_message)\n                return None, f\"TTS failed: {tts_message}\", gr.Dropdown(choices=get_history_choices())\n\n        elif audio_input:\n            if generation_cancelled:\n                return None, \"Cancelled\", gr.Dropdown(choices=get_history_choices())\n            save_status(\"Processing audio\", 10)\n            print(\"Processing audio...\")\n            voice_over_folder_path = '/kaggle/working/voice_over'\n            os.makedirs(voice_over_folder_path, exist_ok=True)\n            voice_filename = f\"upload_{timestamp}.mp3\"\n            saved_voice_path = os.path.join(voice_over_folder_path, voice_filename)\n            shutil.copy2(audio_input, saved_voice_path)\n            voice_over_path = saved_voice_path\n\n        if voice_over_path:\n            try:\n                save_status(\"Processing voiceover\", 20)\n                progress(0.2, desc=\"Processing voice...\")\n                print(\"Processing voiceover...\")\n                \n                voice_over_audio = AudioFileClip(voice_over_path)\n                target_duration_seconds = voice_over_audio.duration\n                linelevel_subtitles, _ = process_voiceover_to_subtitles(voice_over_path)\n\n                if generation_cancelled:\n                    voice_over_audio.close()\n                    return None, \"Cancelled\", gr.Dropdown(choices=get_history_choices())\n                    \n                print(f\"Duration: {target_duration_seconds:.2f}s\")\n                print(f\"Subtitles: {len(linelevel_subtitles)} lines\")\n                \n            except Exception as e:\n                save_status(\"Voice failed\", 20, error=str(e))\n                return None, f\"Voice error: {str(e)}\", gr.Dropdown(choices=get_history_choices())\n\n        save_status(\"Preparing audio\", 30)\n        progress(0.3, desc=\"Audio...\")\n\n        final_audio = None\n        background_music_audio = None\n        \n        if background_music_path:\n            try:\n                print(\"Loading music...\")\n                background_music_audio = AudioFileClip(background_music_path)\n                \n                if background_music_audio.duration < target_duration_seconds:\n                    num_loops = int(target_duration_seconds / background_music_audio.duration) + 1\n                    print(f\"Looping music {num_loops}x\")\n                    audio_clips_to_loop = [background_music_audio] * num_loops\n                    background_music_audio = concatenate_audioclips(audio_clips_to_loop)\n                \n                background_music_audio = background_music_audio.subclip(0, target_duration_seconds)\n                background_music_audio = background_music_audio.volumex(0.025)\n                print(f\"Music ready: {background_music_audio.duration:.2f}s at 2.5%\")\n                \n            except Exception as e:\n                print(f\"Music error: {e}\")\n                background_music_audio = None\n        \n        if voice_over_audio and background_music_audio:\n            final_audio = CompositeAudioClip([voice_over_audio, background_music_audio])\n            print(\"Combined voice + music\")\n        elif voice_over_audio:\n            final_audio = voice_over_audio\n            print(\"Voice only\")\n        elif background_music_audio:\n            final_audio = background_music_audio\n            print(\"Music only\")\n\n        save_status(\"Setting up video\", 35)\n        progress(0.4, desc=\"Setup...\")\n\n        if generation_cancelled:\n            cleanup_resources()\n            return None, \"Cancelled\", gr.Dropdown(choices=get_history_choices())\n\n        target_width, target_height = calculate_target_dimensions(aspect_ratio, video_quality)\n        \n        if video_quality == \"High\":\n            bitrate, preset, crf = \"8000k\", \"veryfast\", \"20\"\n        elif video_quality == \"Standard\":\n            bitrate, preset, crf = \"4000k\", \"veryfast\", \"24\"\n        else:\n            bitrate, preset, crf = \"1000k\", \"ultrafast\", \"28\"\n\n        save_status(\"Processing clips\", 40)\n        progress(0.5, desc=\"Clips...\")\n\n        buffer_seconds = 5.0\n        target_with_buffer = target_duration_seconds + buffer_seconds\n\n        video_clips = []\n        current_duration = 0\n\n        ratio_name = ASPECT_RATIOS[aspect_ratio][\"name\"]\n\n        for i, video_file in enumerate(all_files):\n            if generation_cancelled:\n                for clip in video_clips:\n                    try: clip.close()\n                    except: pass\n                cleanup_resources()\n                return None, \"Cancelled\", gr.Dropdown(choices=get_history_choices())\n\n            if current_duration >= target_with_buffer:\n                break\n\n            try:\n                print(f\"Clip {i+1}: {video_file}\")\n                full_clip = VideoFileClip(os.path.join(source_path, video_file))\n                current_video_clip = full_clip\n\n                if generation_cancelled:\n                    full_clip.close()\n                    cleanup_resources()\n                    return None, \"Cancelled\", gr.Dropdown(choices=get_history_choices())\n\n                full_clip = adapt_vertical_to_format(full_clip, target_width, target_height, aspect_ratio)\n                \n                if ratio_name == \"9:16\":\n                    full_clip = ensure_even_dimensions(full_clip)\n\n                subclip = get_random_subclip_and_slow(full_clip)\n\n                remaining_time = target_with_buffer - current_duration\n                if subclip.duration > remaining_time:\n                    subclip = subclip.subclip(0, remaining_time)\n\n                video_clips.append(subclip)\n                current_duration += subclip.duration\n\n                if i % 5 == 0:\n                    save_status(f\"Clips ({i+1}/{len(all_files)})\", 40 + int((i/len(all_files)) * 15))\n\n                progress(0.5 + (i * 0.1 / len(all_files)), desc=f\"Clip {i+1}\")\n\n            except Exception as e:\n                print(f\"Clip error {video_file}: {e}\")\n                continue\n\n        if generation_cancelled:\n            for clip in video_clips:\n                try: clip.close()\n                except: pass\n            cleanup_resources()\n            return None, \"Cancelled\", gr.Dropdown(choices=get_history_choices())\n\n        if not video_clips:\n            save_status(\"No clips processed\", 0, error=\"No clips\")\n            return None, \"No clips processed\", gr.Dropdown(choices=get_history_choices())\n\n        save_status(\"Concatenating\", 60)\n        progress(0.6, desc=\"Concatenating...\")\n\n        if generation_cancelled:\n            for c in video_clips:\n                try: c.close()\n                except: pass\n            cleanup_resources()\n            return None, \"Cancelled\", gr.Dropdown(choices=get_history_choices())\n\n        final_video_only = concatenate_videoclips(video_clips, method=\"compose\")\n\n        if final_video_only.duration > target_duration_seconds:\n            final_video_only = final_video_only.subclip(0, target_duration_seconds)\n        elif final_video_only.duration < target_duration_seconds:\n            shortage = target_duration_seconds - final_video_only.duration\n            if shortage > 0 and len(video_clips) > 0:\n                last_clip = video_clips[-1]\n                if last_clip.duration > 0:\n                    fill_clip = last_clip.loop(duration=shortage)\n                    final_video_only = concatenate_videoclips([final_video_only, fill_clip])\n\n        if ratio_name == \"9:16\":\n            final_video_only = ensure_even_dimensions(final_video_only)\n\n        current_video_clip = final_video_only\n\n        save_status(\"Adding subtitles\", 70)\n        progress(0.7, desc=\"Subtitles...\")\n\n        if generation_cancelled:\n            try: final_video_only.close()\n            except: pass\n            cleanup_resources()\n            return None, \"Cancelled\", gr.Dropdown(choices=get_history_choices())\n\n        all_subtitle_clips = []\n        if linelevel_subtitles:\n            video_duration = final_video_only.duration\n            valid_subtitles = []\n\n            for line in linelevel_subtitles:\n                if line.get('start', 0) < video_duration:\n                    if line.get('end', 0) > video_duration:\n                        line['end'] = video_duration\n                        for word in line.get('textcontents', []):\n                            if word.get('end', 0) > video_duration:\n                                word['end'] = video_duration\n                    valid_subtitles.append(line)\n\n            for line in valid_subtitles:\n                if generation_cancelled:\n                    try: final_video_only.close()\n                    except: pass\n                    cleanup_resources()\n                    return None, \"Cancelled\", gr.Dropdown(choices=get_history_choices())\n                try:\n                    subtitle_clips = create_caption(line, final_video_only.size,\n                                                  font=\"Helvetica-Bold\",\n                                                  fontsize=get_subtitle_font_size(aspect_ratio, final_video_only.size[1]),\n                                                  color='white',\n                                                  aspect_ratio=aspect_ratio)\n                    all_subtitle_clips.extend(subtitle_clips)\n                except Exception as e:\n                    print(f\"Subtitle error: {e}\")\n                    continue\n\n        all_clips = [final_video_only] \n        if all_subtitle_clips:\n            all_clips.extend(all_subtitle_clips)\n\n        should_add_title = auto_title_enabled and title_text and title_text.strip()\n        if should_add_title:\n            save_status(\"Adding title\", 75)\n            print(f\"‚ú® Adding title overlay: '{title_text}'\")\n            print(f\"   (Title was also spoken in voice-over)\")\n            title_duration = min(4, final_video_only.duration * 0.8)\n            try:\n                title_clips = create_title_overlay(title_text, final_video_only.size, \n                                                   duration=title_duration,\n                                                   aspect_ratio=aspect_ratio)\n                if title_clips:\n                    all_clips.extend(title_clips)\n                    print(f\"‚úÖ Title overlay added successfully\")\n                else:\n                    print(f\"‚ö†Ô∏è Title overlay returned empty\")\n            except Exception as e:\n                print(f\"‚ùå Title error: {e}\")\n        else:\n            print(f\"‚≠ï Skipping title overlay (auto_title_enabled={auto_title_enabled}, title_text='{title_text}')\")\n\n        save_status(\"Compositing\", 78)\n        final_video = CompositeVideoClip(all_clips)\n\n        if final_video.duration > target_duration_seconds:\n            final_video = final_video.subclip(0, target_duration_seconds)\n\n        current_video_clip = final_video\n\n        if final_audio:\n            audio_duration = final_audio.duration\n            video_duration = final_video.duration\n\n            if abs(audio_duration - video_duration) > 0.1:\n                if audio_duration > video_duration:\n                    final_audio = final_audio.subclip(0, video_duration)\n                else:\n                    final_video = final_video.subclip(0, audio_duration)\n\n            final_video = final_video.set_audio(final_audio)\n\n        save_status(\"Exporting\", 80)\n        progress(0.8, desc=\"Exporting...\")\n\n        if generation_cancelled:\n            try: final_video.close()\n            except: pass\n            cleanup_resources()\n            return None, \"Cancelled\", gr.Dropdown(choices=get_history_choices())\n\n        ratio_name_filename = ASPECT_RATIOS[aspect_ratio][\"name\"].replace(\":\", \"x\")\n        if part_number and total_parts:\n            output_filename = f'video_{ratio_name_filename}_part{part_number}of{total_parts}_{timestamp}.mp4'\n        else:\n            output_filename = f'video_{ratio_name_filename}_{timestamp}.mp4'\n        final_output_path = os.path.join(OUTPUT_PATH, output_filename)\n\n        try:\n            final_video.write_videofile(\n                final_output_path, codec=\"libx264\", audio_codec=\"aac\", fps=24, preset=preset,\n                bitrate=bitrate, audio_bitrate=\"128k\", threads=8,\n                ffmpeg_params=[\n                    \"-crf\", crf, \"-pix_fmt\", \"yuv420p\", \"-movflags\", \"+faststart\",\n                    \"-tune\", \"fastdecode\", \"-avoid_negative_ts\", \"make_zero\",\n                    \"-fflags\", \"+genpts\", \"-vsync\", \"1\"\n                ]\n            )\n        except Exception as e:\n            if generation_cancelled:\n                save_status(\"Cancelled\", 80, error=\"Cancelled\")\n                return None, \"Cancelled\", gr.Dropdown(choices=get_history_choices())\n            save_status(\"Export failed\", 80, error=str(e))\n            return None, f\"Export error: {str(e)}\", gr.Dropdown(choices=get_history_choices())\n\n        save_status(\"Complete\", 100, output_path=final_output_path)\n        progress(1.0, desc=\"Complete\")\n\n        if generation_cancelled:\n            try:\n                if os.path.exists(final_output_path): os.remove(final_output_path)\n            except: pass\n            cleanup_resources()\n            return None, \"Cancelled\", gr.Dropdown(choices=get_history_choices())\n\n        try:\n            final_video.close()\n            if voice_over_audio: voice_over_audio.close()\n            if background_music_audio: background_music_audio.close()\n            for clip in video_clips: clip.close()\n            current_video_clip = None\n        except:\n            pass\n\n        audio_source = \"\"\n        if text_input and text_input.strip():\n            audio_source = f\"TTS ({AVAILABLE_VOICES.get(voice_selection, {}).get('name', 'Puck')})\"\n        elif voice_over_path:\n            audio_source = \"Uploaded\"\n        else:\n            audio_source = \"Silent\"\n        \n        if background_music_path:\n            audio_source += \" + Music\"\n\n        try:\n            test_clip = VideoFileClip(final_output_path)\n            final_duration = test_clip.duration\n            test_clip.close()\n        except:\n            final_duration = target_duration_seconds\n\n        metadata = {\n            'duration': round(final_duration, 1),\n            'audio_type': audio_source, 'quality': video_quality,\n            'aspect_ratio': ASPECT_RATIOS[aspect_ratio][\"name\"],\n            'title': title_text if title_text else \"Untitled\",\n            'subtitle_lines': len(linelevel_subtitles) if linelevel_subtitles else 0,\n            'video_folder': os.path.basename(source_path),\n            'music_file': os.path.basename(background_music_path) if background_music_path else \"None\",\n            'part_number': part_number, 'total_parts': total_parts,\n            'auto_title_used': auto_title_enabled,\n            'title_in_voice': auto_title_enabled\n        }\n        save_to_history(final_output_path, metadata)\n\n        summary = f\"\"\"‚úÖ Complete!\n\n{output_filename}\nFormat: {ASPECT_RATIOS[aspect_ratio][\"name\"]}\nDuration: {final_duration:.1f}s\nAudio: {audio_source}\nSubtitles: {len(linelevel_subtitles)} lines\nTitle: {f\"'{title_text}' (spoken + overlay)\" if (auto_title_enabled and title_text) else \"Disabled\"}\"\"\"\n\n        if part_number and total_parts:\n            summary = f\"‚úÖ Video {part_number}/{total_parts} Complete!\\\\n\\\\n\" + summary\n\n        updated_history = get_history_choices()\n        return final_output_path, summary, gr.Dropdown(choices=updated_history, value=final_output_path)\n\n    except Exception as e:\n        save_status(\"Error\", 0, error=str(e))\n        cleanup_resources()\n        import traceback\n        traceback.print_exc()\n        return None, f\"Error: {str(e)}\", gr.Dropdown(choices=get_history_choices())","metadata":{"_uuid":"a22ab37c-e694-4e06-a50a-f9cdad655f3b","_cell_guid":"332f8f98-305b-46fb-9233-5c70947fe00d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Telegram BOT**","metadata":{}},{"cell_type":"code","source":"# ==========================================\n# PART 13: TELEGRAM BOT - BATCH WAIT & ORDERED SEND\n# ==========================================\n\nprint(\"=\"*60)\nprint(\"ü§ñ INITIALIZING TELEGRAM BOT (WAIT-FOR-ALL STRATEGY)\")\nprint(\"=\"*60)\n\nimport subprocess\nimport sys\nimport os\nimport json\nimport time\nimport requests\nimport threading\nimport copy\nimport random\nfrom datetime import datetime\nfrom threading import Thread, Lock, Event\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\n# üì¶ Install Proglog for Progress Tracking\nsubprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"proglog\", \"requests\"])\nfrom proglog import ProgressBarLogger\nfrom moviepy.editor import VideoFileClip\n\n# ==========================================\n# üõ†Ô∏è MONKEY PATCH: REAL-TIME EXPORT TRACKER\n# ==========================================\nclass TelegramExportLogger(ProgressBarLogger):\n    def __init__(self, callback, init_state=None, bars=None, min_time_interval=None):\n        super().__init__(init_state, bars, min_time_interval)\n        self.callback = callback\n        self.last_update = 0\n\n    def callback(self, **changes): pass\n\n    def bars_callback(self, bar, attr, value, old_value=None):\n        if bar == 't':\n            percentage = (value / self.bars[bar]['total']) * 100\n            # Map 0-100% render time to 80-100% overall progress\n            overall_progress = 0.80 + (percentage / 100) * 0.19\n            if percentage - self.last_update > 5:\n                self.callback(overall_progress, f\"Exporting {int(percentage)}% ‚öôÔ∏è\")\n                self.last_update = percentage\n\nif not hasattr(VideoFileClip, '_original_write_videofile'):\n    VideoFileClip._original_write_videofile = VideoFileClip.write_videofile\n\ndef patched_write_videofile(self, filename, **kwargs):\n    return VideoFileClip._original_write_videofile(self, filename, **kwargs)\n\nVideoFileClip.write_videofile = patched_write_videofile\n\n# ==========================================\n# CONFIGURATION\n# ==========================================\n\nTELEGRAM_BOT_TOKEN = \"8424924694:AAG39fxw0eS_KZXoOlv1rggWvaZMg_OJftw\"\nTELEGRAM_API_URL = f\"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}\"\n\n# üöÄ BATCH SIZE LIMIT (Processing power safety)\nBATCH_SIZE = 12\n\nuser_data = {}\nuser_busy_state = {} \nbusy_lock = Lock() \nsending_lock = Lock()\nlast_update_id = 0\n\n# ==========================================\n# STATE & SEQUENCE MANAGEMENT\n# ==========================================\n\nclass BatchStateManager:\n    def __init__(self, total_videos):\n        self.total = total_videos\n        self.lock = Lock()\n        # Stores status for UI: waiting, processing, generated, failed\n        self.videos = {i: {'status': 'waiting', 'step': 'Queued', 'progress': 0.0} \n                       for i in range(1, total_videos + 1)}\n        # Stores final paths to send later\n        self.results = {} \n\n    def update_progress(self, index, progress, step_desc):\n        \"\"\"Update progress for the UI only\"\"\"\n        with self.lock:\n            if index in self.videos:\n                if progress > self.videos[index]['progress']:\n                    self.videos[index]['progress'] = progress\n                self.videos[index]['step'] = step_desc\n                if progress > 0 and self.videos[index]['status'] == 'waiting':\n                    self.videos[index]['status'] = 'processing'\n\n    def mark_completed(self, index, video_path, title, success):\n        \"\"\"Store result but DO NOT send yet\"\"\"\n        with self.lock:\n            if not success:\n                self.videos[index]['status'] = 'failed'\n                self.videos[index]['step'] = 'Failed ‚ùå'\n                self.results[index] = {'success': False}\n            else:\n                self.videos[index]['status'] = 'generated'\n                self.videos[index]['step'] = 'Done (Waiting to send) üì¶'\n                self.videos[index]['progress'] = 1.0\n                self.results[index] = {\n                    'success': True,\n                    'path': video_path,\n                    'title': title\n                }\n\n    def get_snapshot(self):\n        with self.lock:\n            return copy.deepcopy(self.videos)\n    \n    def get_final_results(self):\n        \"\"\"Retrieve all results for sequential sending\"\"\"\n        with self.lock:\n            return copy.deepcopy(self.results)\n\n# ==========================================\n# TELEGRAM API FUNCTIONS\n# ==========================================\n\ndef send_message(chat_id, text, buttons=None):\n    try:\n        url = f\"{TELEGRAM_API_URL}/sendMessage\"\n        data = {'chat_id': chat_id, 'text': text, 'parse_mode': 'Markdown'}\n        if buttons: data['reply_markup'] = json.dumps({'inline_keyboard': buttons})\n        requests.post(url, json=data, timeout=10)\n    except Exception as e: print(f\"‚ùå Send error: {e}\")\n\ndef edit_message(chat_id, message_id, text, buttons=None):\n    try:\n        url = f\"{TELEGRAM_API_URL}/editMessageText\"\n        data = {'chat_id': chat_id, 'message_id': message_id, 'text': text, 'parse_mode': 'Markdown'}\n        if buttons: data['reply_markup'] = json.dumps({'inline_keyboard': buttons})\n        requests.post(url, json=data, timeout=10)\n    except: pass\n\ndef answer_callback(callback_id):\n    try: requests.post(f\"{TELEGRAM_API_URL}/answerCallbackQuery\", json={'callback_query_id': callback_id}, timeout=5)\n    except: pass\n\ndef send_video_atomic(chat_id, video_path, title, caption=\"\"):\n    \"\"\"Sends Title + Video\"\"\"\n    with sending_lock:\n        try:\n            if title and title.strip():\n                send_message(chat_id, f\"*{title}*\")\n                time.sleep(0.5) \n            \n            print(f\"üì§ Uploading: {os.path.basename(video_path)}\")\n            url = f\"{TELEGRAM_API_URL}/sendVideo\"\n            with open(video_path, 'rb') as video:\n                files = {'video': video}\n                data = {'chat_id': chat_id, 'caption': caption, 'supports_streaming': True}\n                response = requests.post(url, data=data, files=files, timeout=600)\n                return response.status_code == 200 and response.json().get('ok')\n        except Exception as e:\n            print(f\"‚ùå Upload Error: {e}\")\n            return False\n\ndef get_updates(offset=None):\n    try:\n        url = f\"{TELEGRAM_API_URL}/getUpdates\"\n        params = {'timeout': 30, 'offset': offset}\n        response = requests.get(url, params=params, timeout=35)\n        return response.json()\n    except: return None\n\n# ==========================================\n# HELPER FUNCTIONS\n# ==========================================\n\ndef is_user_busy(user_id):\n    with busy_lock: return user_busy_state.get(user_id, False)\n\ndef set_user_busy(user_id, busy=True):\n    with busy_lock: user_busy_state[user_id] = busy\n\ndef init_user(user_id):\n    if user_id not in user_data:\n        user_data[user_id] = {\n            'script': '', 'voice': 'Puck', 'aspect': '9:16 (Vertical)',\n            'quality': 'High', 'auto_title': True, 'dataset': None\n        }\n    return user_data[user_id]\n\ndef get_dataset_options():\n    datasets = get_dataset_list()\n    if not datasets: return None\n    return [[{'text': f\"üìÅ {ds['label']}\", 'callback_data': f\"dataset_{ds['name']}\"}] for ds in datasets]\n\ndef get_progress_bar(progress, length=8):\n    filled = int(progress * length)\n    return \"‚ñì\" * filled + \"‚ñë\" * (length - filled)\n\n# ==========================================\n# üöÄ BATCH ENGINE (PARALLEL GEN -> WAIT -> SEQUENTIAL SEND)\n# ==========================================\n\ndef ui_updater_thread(chat_id, message_id, state_manager, stop_event, batch_num, total_batches):\n    \"\"\"Updates Telegram UI with generation status\"\"\"\n    last_text = \"\"\n    while not stop_event.is_set():\n        try:\n            videos = state_manager.get_snapshot()\n            total = len(videos)\n            \n            # Count completion\n            completed = sum(1 for v in videos.values() if v['status'] == 'generated')\n            failed = sum(1 for v in videos.values() if v['status'] == 'failed')\n            \n            text = f\"üöÄ *Processing Batch {batch_num}/{total_batches}*\\n\"\n            text += f\"‚è≥ Status: {completed}/{total} Generated\\n\"\n            text += f\"üõë Failed: {failed}\\n\"\n            text += f\"üîí _Files will be sent after ALL finished_\\n\"\n            text += f\"{'-'*20}\\n\"\n            \n            for i in range(1, total + 1):\n                v = videos[i]\n                pct = int(v['progress'] * 100)\n                step = v['step']\n                \n                if v['status'] == 'generated':\n                    line = f\"{i}. ‚úÖ Ready\\n\"\n                elif v['status'] == 'failed':\n                    line = f\"{i}. ‚ùå Failed\\n\"\n                else:\n                    icon = \"‚öôÔ∏è\" if \"Exporting\" in step else \"üîÑ\"\n                    p_bar = get_progress_bar(v['progress'])\n                    line = f\"{i}. {icon} {p_bar} {pct}% ({step})\\n\"\n                text += line\n\n            text += f\"\\n‚è≥ Updates every 3s...\"\n            \n            if text != last_text:\n                edit_message(chat_id, message_id, text)\n                last_text = text\n            \n            time.sleep(3)\n            \n        except Exception as e:\n            print(f\"UI Error: {e}\")\n            time.sleep(5)\n\ndef handle_bulk_generation(chat_id, message_id, full_script, \n                           voice, aspect, quality, auto_title,\n                           video_folder, music_folder):\n    \n    raw_parts = [p.strip() for p in full_script.split(\"---\") if p.strip()]\n    total_videos = len(raw_parts)\n    \n    # Split large requests into batches to manage resources, but logic remains the same\n    batches = [raw_parts[i:i + BATCH_SIZE] for i in range(0, total_videos, BATCH_SIZE)]\n    total_batches = len(batches)\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"üöÄ JOB STARTED: {total_videos} Videos\")\n    print(f\"‚ö° Strategy: Wait for ALL -> Serial Send\")\n    print(f\"{'='*60}\")\n\n    global_index_offset = 0\n\n    for batch_idx, batch_scripts in enumerate(batches):\n        current_batch_num = batch_idx + 1\n        batch_len = len(batch_scripts)\n        \n        # Initialize Batch State\n        state_manager = BatchStateManager(batch_len)\n        \n        # Start UI Thread\n        stop_ui = Event()\n        ui_thread = Thread(target=ui_updater_thread, args=(chat_id, message_id, state_manager, stop_ui, current_batch_num, total_batches))\n        ui_thread.start()\n\n        # Worker Function\n        def process_video(local_idx, text):\n            actual_part_num = global_index_offset + local_idx\n            try:\n                title = extract_title_from_script(text) if auto_title else \"\"\n                duration = estimate_script_duration(text)\n                \n                time.sleep(random.uniform(0.5, 2.0)) # API Anti-collision\n                \n                def progress_tracker(p, desc=\"\"):\n                    if \"Audio\" in desc: time.sleep(0.2)\n                    if \"Clips\" in desc: time.sleep(0.2)\n                    state_manager.update_progress(local_idx, p, desc)\n\n                export_logger = TelegramExportLogger(\n                    callback=lambda p, d: state_manager.update_progress(local_idx, p, d)\n                )\n                \n                video_path, _, _ = generate_single_video_with_retry(\n                    text_input=text, voice_selection=voice, audio_input=None,\n                    title_text=title, duration_minutes=duration,\n                    video_quality=quality, aspect_ratio=aspect,\n                    video_folder_path=video_folder, music_folder_path=music_folder,\n                    auto_title_enabled=auto_title,\n                    progress=progress_tracker,\n                    part_number=actual_part_num, total_parts=total_videos\n                )\n                \n                # Store Result (Internal)\n                success = bool(video_path and os.path.exists(video_path))\n                state_manager.mark_completed(local_idx, video_path, title, success)\n\n            except Exception as e:\n                print(f\"Video Error: {e}\")\n                state_manager.mark_completed(local_idx, None, None, False)\n\n        # 1. PARALLEL GENERATION PHASE\n        with ThreadPoolExecutor(max_workers=BATCH_SIZE) as executor:\n            futures = [executor.submit(process_video, i+1, txt) for i, txt in enumerate(batch_scripts)]\n            for future in as_completed(futures):\n                try: future.result()\n                except: pass\n        \n        # Stop UI thread after generation finishes\n        stop_ui.set()\n        ui_thread.join()\n        \n        # 2. SEQUENTIAL SENDING PHASE\n        # Generation is complete. Now we send results one by one.\n        send_message(chat_id, f\"‚úÖ *Batch {current_batch_num} Generated! Sending files now...*\")\n        \n        results = state_manager.get_final_results()\n        \n        # Sort by index to ensure strict order (1, 2, 3...)\n        sorted_indices = sorted(results.keys())\n        \n        for idx in sorted_indices:\n            res = results[idx]\n            actual_display_num = global_index_offset + idx\n            \n            if res['success']:\n                caption = f\"Video {actual_display_num}/{total_videos}\"\n                send_message(chat_id, f\"üì§ Uploading Video {actual_display_num}...\")\n                success = send_video_atomic(chat_id, res['path'], res['title'], caption)\n                \n                if not success:\n                    send_message(chat_id, f\"‚ùå Failed to upload Video {actual_display_num}\")\n                \n                # Small buffer to prevent Telegram flooding/disordering\n                time.sleep(1.5)\n            else:\n                send_message(chat_id, f\"‚ùå Generation failed for Video {actual_display_num}\")\n        \n        global_index_offset += batch_len\n\n    send_message(chat_id, \"üéâ *All Videos Delivered!*\")\n\n# ==========================================\n# MESSAGE PROCESSING\n# ==========================================\n\ndef process_message(message):\n    chat_id = message['chat']['id']\n    text = message.get('text', '').strip()\n    \n    if is_user_busy(chat_id) and text != '/start':\n        send_message(chat_id, \"‚ö†Ô∏è *Busy!* Finishing previous job...\")\n        return\n\n    if text == '/start':\n        init_user(chat_id)\n        send_message(chat_id, \n            \"ü§ñ *Video Bot (Strictly Ordered)*\\n\\n\"\n            \"‚ö° *Generation:* Parallel (Wait for all)\\n\"\n            \"üì¶ *Delivery:* Strictly Ordered (1, 2, 3...)\\n\\n\"\n            \"üì• Send multiple scripts separated by `---`\"\n        )\n    elif not text.startswith('/'):\n        init_user(chat_id)\n        user_data[chat_id]['script'] = text\n        count = len([p for p in text.split(\"---\") if p.strip()])\n        send_message(chat_id, f\"‚úÖ Received {count} scripts! Configuring...\")\n        \n        buttons = get_dataset_options()\n        if buttons: send_message(chat_id, \"üìÅ Select Dataset:\", buttons)\n        else: send_message(chat_id, \"‚ö†Ô∏è No datasets found\")\n\ndef process_callback(callback_query):\n    chat_id = callback_query['message']['chat']['id']\n    msg_id = callback_query['message']['message_id']\n    data = callback_query['data']\n    answer_callback(callback_query['id'])\n    \n    if is_user_busy(chat_id): return\n    u = init_user(chat_id)\n    \n    if data.startswith('dataset_'):\n        u['dataset'] = data.replace('dataset_', '')\n        edit_message(chat_id, msg_id, f\"‚úÖ Dataset: {u['dataset']}\")\n        btns = [[{'text': f\"{v['name']}\", 'callback_data': f\"voice_{k}\"}] for k,v in AVAILABLE_VOICES.items()]\n        edit_message(chat_id, msg_id, \"üéôÔ∏è Choose Voice:\", btns)\n        \n    elif data.startswith('voice_'):\n        u['voice'] = data.replace('voice_', '')\n        btns = [[{'text': k, 'callback_data': f\"aspect_{k}\"}] for k in ASPECT_RATIOS.keys()]\n        edit_message(chat_id, msg_id, \"üìê Choose Aspect:\", btns)\n        \n    elif data.startswith('aspect_'):\n        u['aspect'] = data.replace('aspect_', '')\n        btns = [[{'text': 'üåü High', 'callback_data': 'quality_High'}], [{'text': '‚ö° Standard', 'callback_data': 'quality_Standard'}]]\n        edit_message(chat_id, msg_id, \"üé¨ Choose Quality:\", btns)\n        \n    elif data.startswith('quality_'):\n        u['quality'] = data.replace('quality_', '')\n        btns = [[{'text': '‚úÖ Yes', 'callback_data': 'title_yes'}], [{'text': '‚ùå No', 'callback_data': 'title_no'}]]\n        edit_message(chat_id, msg_id, \"üéØ Auto Title?\", btns)\n        \n    elif data.startswith('title_'):\n        u['auto_title'] = (data == 'title_yes')\n        parts = len([p for p in u['script'].split(\"---\") if p.strip()])\n        summary = f\"‚úÖ *Ready*\\n\\nüìπ Videos: {parts}\\n‚ö° Gen: Parallel\\nüîí Send: Wait for all\\n\\nStart?\"\n        btns = [[{'text': 'üöÄ GO!', 'callback_data': 'generate_now'}]]\n        edit_message(chat_id, msg_id, summary, btns)\n        \n    elif data == 'generate_now':\n        set_user_busy(chat_id, True)\n        edit_message(chat_id, msg_id, \"üöÄ *Initializing Batch... (No messages until finish)*\")\n        \n        v_path = get_dataset_by_name(u['dataset']) if u['dataset'] else None\n        if not v_path:\n             dfs, _ = scan_available_folders()\n             if dfs: v_path = dfs[0]['path']\n        m_path = get_default_music_folder()\n        \n        thread = Thread(target=lambda: [\n            handle_bulk_generation(chat_id, msg_id, u['script'], u['voice'], \n                                   u['aspect'], u['quality'], u['auto_title'], \n                                   v_path, m_path),\n            set_user_busy(chat_id, False)\n        ])\n        thread.start()\n\n# ==========================================\n# MAIN LOOP\n# ==========================================\n\ndef run_bot():\n    global last_update_id\n    print(\"üöÄ Bot polling started...\")\n    while True:\n        try:\n            updates = get_updates(last_update_id + 1)\n            if updates and updates.get('ok'):\n                for u in updates.get('result', []):\n                    last_update_id = u['update_id']\n                    if 'message' in u: process_message(u['message'])\n                    elif 'callback_query' in u: process_callback(u['callback_query'])\n        except Exception as e:\n            print(f\"Poll Error: {e}\")\n            time.sleep(5)\n\nt = Thread(target=run_bot, daemon=True)\nt.start()\n\ntry:\n    while True: time.sleep(10)\nexcept KeyboardInterrupt:\n    print(\"Stopped\")","metadata":{"_uuid":"b9ce292f-fb97-43cd-85c0-d03cd7842b3c","_cell_guid":"f6345886-33fb-45dc-b8f1-3067ded08ebe","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **OUTPUT**","metadata":{"_uuid":"b574898a-867d-4442-9274-7cf183651b9b","_cell_guid":"e1d5cd54-fd4a-4cdf-acf6-9a9ef5934a5d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}}]}